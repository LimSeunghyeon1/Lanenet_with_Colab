{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lanenet_for_test",
      "provenance": [],
      "authorship_tag": "ABX9TyNRViJsVgonwaQltdd5OSqM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LimSeunghyeon1/Lanenet_with_Colab/blob/master/Lanenet_for_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YythAK3OeWd",
        "outputId": "c5638fed-ebc6-4b74-ef25-8648d72a1a39"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3NQ6wBRP2Bk"
      },
      "source": [
        "! #unzip -d /content/drive/Shareddrives/colab/ /content/drive/MyDrive/Apollo_Sim_3D_Lane_Release.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz9ubvWueepY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_VXWTs-eeyb"
      },
      "source": [
        "\"\"\"\n",
        "Utility functions and default settings\n",
        "Author: Yuliang Guo (33yuliangguo@gmail.com)\n",
        "Date: March, 2020\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import errno\n",
        "import os\n",
        "import sys\n",
        "import easydict\n",
        "\n",
        "import cv2\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.init as init\n",
        "import torch.optim\n",
        "from torch.optim import lr_scheduler\n",
        "import os.path as ops\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import interp1d\n",
        "plt.rcParams['figure.figsize'] = (35, 30)\n",
        "\n",
        "\n",
        "def define_args():\n",
        "    parser=easydict.EasyDict({\n",
        "       \"dataset_name\":str(),\n",
        "       \"data_dir\":str(),\n",
        "       \"dataset_dir\":str(),\n",
        "       \"save_path\":'/content/drive/Shareddrives/colab/data_splits',\n",
        "       \"org_h\":1080,\n",
        "       \"org_w\":1920,\n",
        "       \"crop_y\":0,\n",
        "       \"cam_height\":1.55,\n",
        "       \"pitch\":float(3),\n",
        "       \"fix_cam\":False,\n",
        "       \"no_3d\": False,\n",
        "       \"no_centerline\":False,\n",
        "       \"mod\":'3DLaneNet',\n",
        "       \"pretrained\":True,\n",
        "       \"batch_norm\":True,\n",
        "       \"pred_cam\":False,\n",
        "       \"ipm_h\":208,\n",
        "       \"ipm_w\":128,\n",
        "       \"resize_h\":360,\n",
        "       \"resize_w\":480,\n",
        "       \"y_ref\":20.0,\n",
        "       \"prob_th\":0.5,\n",
        "       \"batch_size\":8,\n",
        "       \"nepochs\":30,\n",
        "       \"learning_rate\":5*1e-4,\n",
        "       \"no_cuda\":False,\n",
        "       \"nworkers\":0,\n",
        "       \"no_dropout\":False,\n",
        "       \"pretrain_epochs\":20,\n",
        "       \"channels_in\":3,\n",
        "       \"flip_on\":False,\n",
        "       \"test_mode\":False,\n",
        "       \"start_epoch\":0,\n",
        "       \"evaluate\":True,  ##only show evaluation?\n",
        "       \"resume\":str(),\n",
        "       \"vgg_mean\":[0.485,0.456,0.406],\n",
        "       \"vgg_std\":[0.229,0.224,0.225],\n",
        "       \"optimizer\":'adam',\n",
        "       \"weight_init\":\"normal\",\n",
        "       \"weight_decay\":float(0),\n",
        "       \"lr_decay\":False,\n",
        "       \"niter\":50,\n",
        "       \"niter_decay\":400,\n",
        "       \"lr_policy\":None,\n",
        "       \"lr_decay_iters\":30,\n",
        "       \"clip_grad_norm\":0,\n",
        "       \"cudnn\":True,\n",
        "       \"no_tb\":False,\n",
        "       \"print_freq\":500,\n",
        "       \"save_freq\":500,\n",
        "       \"list\":[954,2789]\n",
        "    })\n",
        "    '''\n",
        "    parser = argparse.ArgumentParser(description='Lane_detection_all_objectives')\n",
        "    # Paths settings\n",
        "    parser.add_argument('--dataset_name', type=str, help='the dataset name to be used in saving model names')\n",
        "    parser.add_argument('--data_dir', type=str, help='The path saving train.json and val.json files')\n",
        "    parser.add_argument('--dataset_dir', type=str, help='The path saving actual data')\n",
        "    parser.add_argument('--save_path', type=str, default='data_splits/', help='directory to save output')\n",
        "    # Dataset settings\n",
        "    parser.add_argument('--org_h', type=int, default=1080, help='height of the original image')\n",
        "    parser.add_argument('--org_w', type=int, default=1920, help='width of the original image')\n",
        "    parser.add_argument('--crop_y', type=int, default=0, help='crop from image')\n",
        "    parser.add_argument('--cam_height', type=float, default=1.55, help='height of camera in meters')\n",
        "    parser.add_argument('--pitch', type=float, default=3, help='pitch angle of camera to ground in centi degree')\n",
        "    parser.add_argument('--fix_cam', type=str2bool, nargs='?', const=True, default=False, help='if to use fix camera')\n",
        "    parser.add_argument('--no_3d', action='store_true', help='if a dataset include laneline 3D attributes')\n",
        "    parser.add_argument('--no_centerline', action='store_true', help='if a dataset include centerline')\n",
        "    # 3DLaneNet settings\n",
        "    parser.add_argument('--mod', type=str, default='3DLaneNet', help='model to train')\n",
        "    parser.add_argument(\"--pretrained\", type=str2bool, nargs='?', const=True, default=True, help=\"use pretrained vgg model\")\n",
        "    parser.add_argument(\"--batch_norm\", type=str2bool, nargs='?', const=True, default=True, help=\"apply batch norm\")\n",
        "    parser.add_argument(\"--pred_cam\", type=str2bool, nargs='?', const=True, default=False, help=\"use network to predict camera online?\")\n",
        "    parser.add_argument('--ipm_h', type=int, default=208, help='height of inverse projective map (IPM)')\n",
        "    parser.add_argument('--ipm_w', type=int, default=128, help='width of inverse projective map (IPM)')\n",
        "    parser.add_argument('--resize_h', type=int, default=360, help='height of the original image')\n",
        "    parser.add_argument('--resize_w', type=int, default=480, help='width of the original image')\n",
        "    parser.add_argument('--y_ref', type=float, default=20.0, help='the reference Y distance in meters from where lane association is determined')\n",
        "    parser.add_argument('--prob_th', type=float, default=0.5, help='probability threshold for selecting output lanes')\n",
        "    # General model settings\n",
        "    parser.add_argument('--batch_size', type=int, default=8, help='batch size')\n",
        "    parser.add_argument('--nepochs', type=int, default=30, help='total numbers of epochs')\n",
        "    parser.add_argument('--learning_rate', type=float, default=5*1e-4, help='learning rate')\n",
        "    parser.add_argument('--no_cuda', action='store_true', help='if gpu available')\n",
        "    parser.add_argument('--nworkers', type=int, default=0, help='num of threads')\n",
        "    parser.add_argument('--no_dropout', action='store_true', help='no dropout in network')\n",
        "    parser.add_argument('--pretrain_epochs', type=int, default=20, help='Number of epochs to perform segmentation pretraining')\n",
        "    parser.add_argument('--channels_in', type=int, default=3, help='num channels of input image')\n",
        "    parser.add_argument('--flip_on', action='store_true', help='Random flip input images on?')\n",
        "    parser.add_argument('--test_mode', action='store_true', help='prevents loading latest saved model')\n",
        "    parser.add_argument('--start_epoch', type=int, default=0, help='prevents loading latest saved model')\n",
        "    parser.add_argument('--evaluate', action='store_true', help='only perform evaluation')\n",
        "    parser.add_argument('--resume', type=str, default='', help='resume latest saved run')\n",
        "    parser.add_argument('--vgg_mean', type=float, default=[0.485, 0.456, 0.406], help='Mean of rgb used in pretrained model on ImageNet')\n",
        "    parser.add_argument('--vgg_std', type=float, default=[0.229, 0.224, 0.225], help='Std of rgb used in pretrained model on ImageNet')\n",
        "    # Optimizer settings\n",
        "    parser.add_argument('--optimizer', type=str, default='adam', help='adam or sgd')\n",
        "    parser.add_argument('--weight_init', type=str, default='normal', help='normal, xavier, kaiming, orhtogonal weights initialisation')\n",
        "    parser.add_argument('--weight_decay', type=float, default=0, help='L2 weight decay/regularisation on?')\n",
        "    parser.add_argument('--lr_decay', action='store_true', help='decay learning rate with rule')\n",
        "    parser.add_argument('--niter', type=int, default=50, help='# of iter at starting learning rate')\n",
        "    parser.add_argument('--niter_decay', type=int, default=400, help='# of iter to linearly decay learning rate to zero')\n",
        "    parser.add_argument('--lr_policy', default=None, help='learning rate policy: lambda|step|plateau')\n",
        "    parser.add_argument('--lr_decay_iters', type=int, default=30, help='multiply by a gamma every lr_decay_iters iterations')\n",
        "    parser.add_argument('--clip_grad_norm', type=int, default=0, help='performs gradient clipping')\n",
        "    # CUDNN usage\n",
        "    parser.add_argument(\"--cudnn\", type=str2bool, nargs='?', const=True, default=True, help=\"cudnn optimization active\")\n",
        "    # Tensorboard settings\n",
        "    parser.add_argument(\"--no_tb\", type=str2bool, nargs='?', const=True, default=False, help=\"Use tensorboard logging by tensorflow\")\n",
        "    # Print settings\n",
        "    parser.add_argument('--print_freq', type=int, default=500, help='padding')\n",
        "    parser.add_argument('--save_freq', type=int, default=500, help='padding')\n",
        "    # Skip batch\n",
        "    parser.add_argument('--list', type=int, nargs='+', default=[954, 2789], help='Images you want to skip')\n",
        "'''\n",
        "    return parser\n",
        "\n",
        "\n",
        "def tusimple_config(args):\n",
        "\n",
        "    # set dataset parameters\n",
        "    args.org_h = 720\n",
        "    args.org_w = 1280\n",
        "    args.crop_y = 80\n",
        "    args.no_centerline = True\n",
        "    args.no_3d = True\n",
        "    args.fix_cam = True\n",
        "    args.pred_cam = False\n",
        "\n",
        "    # set camera parameters for the test dataset\n",
        "    args.K = np.array([[1000, 0, 640],\n",
        "                       [0, 1000, 400],\n",
        "                       [0, 0, 1]])\n",
        "    args.cam_height = 1.6\n",
        "    args.pitch = 9\n",
        "\n",
        "    # specify model settings\n",
        "    \"\"\"\n",
        "    paper presented params:\n",
        "        args.top_view_region = np.array([[-10, 85], [10, 85], [-10, 5], [10, 5]])\n",
        "        args.anchor_y_steps = np.array([5, 20, 40, 60, 80, 100])\n",
        "    \"\"\"\n",
        "    # args.top_view_region = np.array([[-10, 82], [10, 82], [-10, 2], [10, 2]])\n",
        "    # args.anchor_y_steps = np.array([2, 3, 5, 10, 15, 20, 30, 40, 60, 80])\n",
        "    args.top_view_region = np.array([[-10, 103], [10, 103], [-10, 3], [10, 3]])\n",
        "    args.anchor_y_steps = np.array([5, 10, 15, 20, 30, 40, 50, 60, 80, 100])\n",
        "    args.num_y_steps = len(args.anchor_y_steps)\n",
        "\n",
        "    # initialize with pre-trained vgg weights\n",
        "    args.pretrained = False\n",
        "    # apply batch norm in network\n",
        "    args.batch_norm = True\n",
        "\n",
        "\n",
        "def sim3d_config(args):\n",
        "\n",
        "    # set dataset parameters\n",
        "    args.org_h = 1080\n",
        "    args.org_w = 1920\n",
        "    args.crop_y = 0\n",
        "    args.no_centerline = False\n",
        "    args.no_3d = False\n",
        "    args.fix_cam = False\n",
        "    args.pred_cam = False\n",
        "\n",
        "    # set camera parameters for the test datasets\n",
        "    args.K = np.array([[2015., 0., 960.],\n",
        "                       [0., 2015., 540.],\n",
        "                       [0., 0., 1.]])\n",
        "\n",
        "    # specify model settings\n",
        "    \"\"\"\n",
        "    paper presented params:\n",
        "        args.top_view_region = np.array([[-10, 85], [10, 85], [-10, 5], [10, 5]])\n",
        "        args.anchor_y_steps = np.array([5, 20, 40, 60, 80, 100])\n",
        "    \"\"\"\n",
        "    # args.top_view_region = np.array([[-10, 83], [10, 83], [-10, 3], [10, 3]])\n",
        "    # args.anchor_y_steps = np.array([3, 5, 10, 20, 40, 60, 80, 100])\n",
        "    args.top_view_region = np.array([[-10, 103], [10, 103], [-10, 3], [10, 3]])\n",
        "    args.anchor_y_steps = np.array([5, 10, 15, 20, 30, 40, 50, 60, 80, 100])\n",
        "    args.num_y_steps = len(args.anchor_y_steps)\n",
        "\n",
        "    # initialize with pre-trained vgg weights\n",
        "    args.pretrained = False\n",
        "    # apply batch norm in network\n",
        "    args.batch_norm = True\n",
        "\n",
        "\n",
        "class Visualizer:\n",
        "    def __init__(self, args, vis_folder='val_vis'):\n",
        "        self.save_path = args.save_path\n",
        "        self.vis_folder = vis_folder\n",
        "        self.no_3d = args.no_3d\n",
        "        self.no_centerline = args.no_centerline\n",
        "        self.vgg_mean = args.vgg_mean\n",
        "        self.vgg_std = args.vgg_std\n",
        "        self.ipm_w = args.ipm_w\n",
        "        self.ipm_h = args.ipm_h\n",
        "        self.num_y_steps = args.num_y_steps\n",
        "\n",
        "        if args.no_3d:\n",
        "            self.anchor_dim = args.num_y_steps + 1\n",
        "        else:\n",
        "            if 'ext' in args.mod:\n",
        "                self.anchor_dim = 3 * args.num_y_steps + 1\n",
        "            else:\n",
        "                self.anchor_dim = 2 * args.num_y_steps + 1\n",
        "\n",
        "        x_min = args.top_view_region[0, 0]\n",
        "        x_max = args.top_view_region[1, 0]\n",
        "        self.anchor_x_steps = np.linspace(x_min, x_max, np.int(args.ipm_w / 8), endpoint=True)\n",
        "        self.anchor_y_steps = args.anchor_y_steps\n",
        "\n",
        "        # transformation from ipm to ground region\n",
        "        H_ipm2g = cv2.getPerspectiveTransform(np.float32([[0, 0],\n",
        "                                                          [self.ipm_w-1, 0],\n",
        "                                                          [0, self.ipm_h-1],\n",
        "                                                          [self.ipm_w-1, self.ipm_h-1]]),\n",
        "                                              np.float32(args.top_view_region))\n",
        "        self.H_g2ipm = np.linalg.inv(H_ipm2g)\n",
        "\n",
        "        # probability threshold for choosing visualize lanes\n",
        "        self.prob_th = args.prob_th\n",
        "\n",
        "    def draw_on_img(self, img, lane_anchor, P_g2im, draw_type='laneline', color=[0, 0, 1]):\n",
        "        \"\"\"\n",
        "        :param img: image in numpy array, each pixel in [0, 1] range\n",
        "        :param lane_anchor: lane anchor in N X C numpy ndarray, dimension in agree with dataloader\n",
        "        :param P_g2im: projection from ground 3D coordinates to image 2D coordinates\n",
        "        :param draw_type: 'laneline' or 'centerline' deciding which to draw\n",
        "        :param color: [r, g, b] color for line,  each range in [0, 1]\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        for j in range(lane_anchor.shape[0]):\n",
        "            # draw laneline\n",
        "            if draw_type is 'laneline' and lane_anchor[j, self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, :self.num_y_steps]\n",
        "                x_3d = x_offsets + self.anchor_x_steps[j]\n",
        "                if P_g2im.shape[1] is 3:\n",
        "                    x_2d, y_2d = homographic_transformation(P_g2im, x_3d, self.anchor_y_steps)\n",
        "                else:\n",
        "                    z_3d = lane_anchor[j, self.num_y_steps:self.anchor_dim - 1]\n",
        "                    x_2d, y_2d = projective_transformation(P_g2im, x_3d, self.anchor_y_steps, z_3d)\n",
        "                x_2d = x_2d.astype(np.int)\n",
        "                y_2d = y_2d.astype(np.int)\n",
        "                for k in range(1, x_2d.shape[0]):\n",
        "                    img = cv2.line(img, (x_2d[k - 1], y_2d[k - 1]), (x_2d[k], y_2d[k]), color, 2)\n",
        "\n",
        "            # draw centerline\n",
        "            if draw_type is 'centerline' and lane_anchor[j, 2 * self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, self.anchor_dim:self.anchor_dim + self.num_y_steps]\n",
        "                x_3d = x_offsets + self.anchor_x_steps[j]\n",
        "                if P_g2im.shape[1] is 3:\n",
        "                    x_2d, y_2d = homographic_transformation(P_g2im, x_3d, self.anchor_y_steps)\n",
        "                else:\n",
        "                    z_3d = lane_anchor[j, self.anchor_dim + self.num_y_steps:2 * self.anchor_dim - 1]\n",
        "                    x_2d, y_2d = projective_transformation(P_g2im, x_3d, self.anchor_y_steps, z_3d)\n",
        "                x_2d = x_2d.astype(np.int)\n",
        "                y_2d = y_2d.astype(np.int)\n",
        "                for k in range(1, x_2d.shape[0]):\n",
        "                    img = cv2.line(img, (x_2d[k - 1], y_2d[k - 1]), (x_2d[k], y_2d[k]), color, 2)\n",
        "\n",
        "            # draw the additional centerline for the merging case\n",
        "            if draw_type is 'centerline' and lane_anchor[j, 3 * self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, 2 * self.anchor_dim:2 * self.anchor_dim + self.num_y_steps]\n",
        "                x_3d = x_offsets + self.anchor_x_steps[j]\n",
        "                if P_g2im.shape[1] is 3:\n",
        "                    x_2d, y_2d = homographic_transformation(P_g2im, x_3d, self.anchor_y_steps)\n",
        "                else:\n",
        "                    z_3d = lane_anchor[j, 2 * self.anchor_dim + self.num_y_steps:3 * self.anchor_dim - 1]\n",
        "                    x_2d, y_2d = projective_transformation(P_g2im, x_3d, self.anchor_y_steps, z_3d)\n",
        "                x_2d = x_2d.astype(np.int)\n",
        "                y_2d = y_2d.astype(np.int)\n",
        "                for k in range(1, x_2d.shape[0]):\n",
        "                    img = cv2.line(img, (x_2d[k - 1], y_2d[k - 1]), (x_2d[k], y_2d[k]), color, 2)\n",
        "        return img\n",
        "\n",
        "    def draw_on_img_new(self, img, lane_anchor, P_g2im, draw_type='laneline', color=[0, 0, 1]):\n",
        "        \"\"\"\n",
        "        :param img: image in numpy array, each pixel in [0, 1] range\n",
        "        :param lane_anchor: lane anchor in N X C numpy ndarray, dimension in agree with dataloader\n",
        "        :param P_g2im: projection from ground 3D coordinates to image 2D coordinates\n",
        "        :param draw_type: 'laneline' or 'centerline' deciding which to draw\n",
        "        :param color: [r, g, b] color for line,  each range in [0, 1]\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        for j in range(lane_anchor.shape[0]):\n",
        "            # draw laneline\n",
        "            if draw_type is 'laneline' and lane_anchor[j, self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, :self.num_y_steps]\n",
        "                x_3d = x_offsets + self.anchor_x_steps[j]\n",
        "                if P_g2im.shape[1] is 3:\n",
        "                    x_2d, y_2d = homographic_transformation(P_g2im, x_3d, self.anchor_y_steps)\n",
        "                    visibility = np.ones_like(x_2d)\n",
        "                else:\n",
        "                    z_3d = lane_anchor[j, self.num_y_steps:2*self.num_y_steps]\n",
        "                    x_2d, y_2d = projective_transformation(P_g2im, x_3d, self.anchor_y_steps, z_3d)\n",
        "                    visibility = lane_anchor[j, 2 * self.num_y_steps:3 * self.num_y_steps]\n",
        "                x_2d = x_2d.astype(np.int)\n",
        "                y_2d = y_2d.astype(np.int)\n",
        "                for k in range(1, x_2d.shape[0]):\n",
        "                    if visibility[k] > self.prob_th:\n",
        "                        img = cv2.line(img, (x_2d[k - 1], y_2d[k - 1]), (x_2d[k], y_2d[k]), color, 2)\n",
        "                    else:\n",
        "                        img = cv2.line(img, (x_2d[k - 1], y_2d[k - 1]), (x_2d[k], y_2d[k]), [0, 0, 0], 2)\n",
        "\n",
        "            # draw centerline\n",
        "            if draw_type is 'centerline' and lane_anchor[j, 2 * self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, self.anchor_dim:self.anchor_dim + self.num_y_steps]\n",
        "                x_3d = x_offsets + self.anchor_x_steps[j]\n",
        "                if P_g2im.shape[1] is 3:\n",
        "                    x_2d, y_2d = homographic_transformation(P_g2im, x_3d, self.anchor_y_steps)\n",
        "                    visibility = np.ones_like(x_2d)\n",
        "                else:\n",
        "                    z_3d = lane_anchor[j, self.anchor_dim + self.num_y_steps:self.anchor_dim + 2*self.num_y_steps]\n",
        "                    x_2d, y_2d = projective_transformation(P_g2im, x_3d, self.anchor_y_steps, z_3d)\n",
        "                    visibility = lane_anchor[j, self.anchor_dim + 2*self.num_y_steps:self.anchor_dim + 3*self.num_y_steps]\n",
        "                x_2d = x_2d.astype(np.int)\n",
        "                y_2d = y_2d.astype(np.int)\n",
        "                for k in range(1, x_2d.shape[0]):\n",
        "                    if visibility[k] > self.prob_th:\n",
        "                        img = cv2.line(img, (x_2d[k - 1], y_2d[k - 1]), (x_2d[k], y_2d[k]), color, 2)\n",
        "                    else:\n",
        "                        img = cv2.line(img, (x_2d[k - 1], y_2d[k - 1]), (x_2d[k], y_2d[k]), [0, 0, 0], 2)\n",
        "\n",
        "            # draw the additional centerline for the merging case\n",
        "            if draw_type is 'centerline' and lane_anchor[j, 3*self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, 2*self.anchor_dim:2*self.anchor_dim + self.num_y_steps]\n",
        "                x_3d = x_offsets + self.anchor_x_steps[j]\n",
        "                if P_g2im.shape[1] is 3:\n",
        "                    x_2d, y_2d = homographic_transformation(P_g2im, x_3d, self.anchor_y_steps)\n",
        "                    visibility = np.ones_like(x_2d)\n",
        "                else:\n",
        "                    z_3d = lane_anchor[j, 2*self.anchor_dim + self.num_y_steps:2*self.anchor_dim + 2*self.num_y_steps]\n",
        "                    x_2d, y_2d = projective_transformation(P_g2im, x_3d, self.anchor_y_steps, z_3d)\n",
        "                    visibility = lane_anchor[j,\n",
        "                                 2 * self.anchor_dim + 2 * self.num_y_steps:2 * self.anchor_dim + 3 * self.num_y_steps]\n",
        "                x_2d = x_2d.astype(np.int)\n",
        "                y_2d = y_2d.astype(np.int)\n",
        "                for k in range(1, x_2d.shape[0]):\n",
        "                    if visibility[k] > self.prob_th:\n",
        "                        img = cv2.line(img, (x_2d[k - 1], y_2d[k - 1]), (x_2d[k], y_2d[k]), color, 2)\n",
        "                    else:\n",
        "                        img = cv2.line(img, (x_2d[k - 1], y_2d[k - 1]), (x_2d[k], y_2d[k]), [0, 0, 0], 2)\n",
        "        return img\n",
        "\n",
        "    def draw_on_ipm(self, im_ipm, lane_anchor, draw_type='laneline', color=[0, 0, 1]):\n",
        "        for j in range(lane_anchor.shape[0]):\n",
        "            # draw laneline\n",
        "            if draw_type is 'laneline' and lane_anchor[j, self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, :self.num_y_steps]\n",
        "                x_g = x_offsets + self.anchor_x_steps[j]\n",
        "\n",
        "                # compute lanelines in ipm view\n",
        "                x_ipm, y_ipm = homographic_transformation(self.H_g2ipm, x_g, self.anchor_y_steps)\n",
        "                x_ipm = x_ipm.astype(np.int)\n",
        "                y_ipm = y_ipm.astype(np.int)\n",
        "                for k in range(1, x_g.shape[0]):\n",
        "                    im_ipm = cv2.line(im_ipm, (x_ipm[k - 1], y_ipm[k - 1]),\n",
        "                                      (x_ipm[k], y_ipm[k]), color, 1)\n",
        "\n",
        "            # draw centerline\n",
        "            if draw_type is 'centerline' and lane_anchor[j, 2 * self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, self.anchor_dim:self.anchor_dim + self.num_y_steps]\n",
        "                x_g = x_offsets + self.anchor_x_steps[j]\n",
        "\n",
        "                # compute lanelines in ipm view\n",
        "                x_ipm, y_ipm = homographic_transformation(self.H_g2ipm, x_g, self.anchor_y_steps)\n",
        "                x_ipm = x_ipm.astype(np.int)\n",
        "                y_ipm = y_ipm.astype(np.int)\n",
        "                for k in range(1, x_g.shape[0]):\n",
        "                    im_ipm = cv2.line(im_ipm, (x_ipm[k - 1], y_ipm[k - 1]),\n",
        "                                      (x_ipm[k], y_ipm[k]), color, 1)\n",
        "\n",
        "            # draw the additional centerline for the merging case\n",
        "            if draw_type is 'centerline' and lane_anchor[j, 3 * self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, 2 * self.anchor_dim:2 * self.anchor_dim + self.num_y_steps]\n",
        "                x_g = x_offsets + self.anchor_x_steps[j]\n",
        "\n",
        "                # compute lanelines in ipm view\n",
        "                x_ipm, y_ipm = homographic_transformation(self.H_g2ipm, x_g, self.anchor_y_steps)\n",
        "                x_ipm = x_ipm.astype(np.int)\n",
        "                y_ipm = y_ipm.astype(np.int)\n",
        "                for k in range(1, x_g.shape[0]):\n",
        "                    im_ipm = cv2.line(im_ipm, (x_ipm[k - 1], y_ipm[k - 1]),\n",
        "                                      (x_ipm[k], y_ipm[k]), color, 1)\n",
        "        return im_ipm\n",
        "\n",
        "    def draw_on_ipm_new(self, im_ipm, lane_anchor, draw_type='laneline', color=[0, 0, 1], width=1):\n",
        "        for j in range(lane_anchor.shape[0]):\n",
        "            # draw laneline\n",
        "            if draw_type is 'laneline' and lane_anchor[j, self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, :self.num_y_steps]\n",
        "                x_g = x_offsets + self.anchor_x_steps[j]\n",
        "                if self.no_3d:\n",
        "                    visibility = np.ones_like(x_g)\n",
        "                else:\n",
        "                    visibility = lane_anchor[j, 2*self.num_y_steps:3*self.num_y_steps]\n",
        "\n",
        "                # compute lanelines in ipm view\n",
        "                x_ipm, y_ipm = homographic_transformation(self.H_g2ipm, x_g, self.anchor_y_steps)\n",
        "                x_ipm = x_ipm.astype(np.int)\n",
        "                y_ipm = y_ipm.astype(np.int)\n",
        "                for k in range(1, x_g.shape[0]):\n",
        "                    if visibility[k] > self.prob_th:\n",
        "                        im_ipm = cv2.line(im_ipm, (x_ipm[k - 1], y_ipm[k - 1]),\n",
        "                                          (x_ipm[k], y_ipm[k]), color, width)\n",
        "                    else:\n",
        "                        im_ipm = cv2.line(im_ipm, (x_ipm[k - 1], y_ipm[k - 1]),\n",
        "                                          (x_ipm[k], y_ipm[k]), [0, 0, 0], width)\n",
        "\n",
        "            # draw centerline\n",
        "            if draw_type is 'centerline' and lane_anchor[j, 2*self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, self.anchor_dim:self.anchor_dim + self.num_y_steps]\n",
        "                x_g = x_offsets + self.anchor_x_steps[j]\n",
        "                if self.no_3d:\n",
        "                    visibility = np.ones_like(x_g)\n",
        "                else:\n",
        "                    visibility = lane_anchor[j, self.anchor_dim + 2*self.num_y_steps:self.anchor_dim + 3*self.num_y_steps]\n",
        "\n",
        "                # compute lanelines in ipm view\n",
        "                x_ipm, y_ipm = homographic_transformation(self.H_g2ipm, x_g, self.anchor_y_steps)\n",
        "                x_ipm = x_ipm.astype(np.int)\n",
        "                y_ipm = y_ipm.astype(np.int)\n",
        "                for k in range(1, x_g.shape[0]):\n",
        "                    if visibility[k] > self.prob_th:\n",
        "                        im_ipm = cv2.line(im_ipm, (x_ipm[k - 1], y_ipm[k - 1]),\n",
        "                                          (x_ipm[k], y_ipm[k]), color, width)\n",
        "                    else:\n",
        "                        im_ipm = cv2.line(im_ipm, (x_ipm[k - 1], y_ipm[k - 1]),\n",
        "                                          (x_ipm[k], y_ipm[k]), [0, 0, 0], width)\n",
        "\n",
        "            # draw the additional centerline for the merging case\n",
        "            if draw_type is 'centerline' and lane_anchor[j, 3*self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, 2*self.anchor_dim:2*self.anchor_dim + self.num_y_steps]\n",
        "                x_g = x_offsets + self.anchor_x_steps[j]\n",
        "                if self.no_3d:\n",
        "                    visibility = np.ones_like(x_g)\n",
        "                else:\n",
        "                    visibility = lane_anchor[j, 2*self.anchor_dim + 2*self.num_y_steps:2*self.anchor_dim + 3*self.num_y_steps]\n",
        "\n",
        "                # compute lanelines in ipm view\n",
        "                x_ipm, y_ipm = homographic_transformation(self.H_g2ipm, x_g, self.anchor_y_steps)\n",
        "                x_ipm = x_ipm.astype(np.int)\n",
        "                y_ipm = y_ipm.astype(np.int)\n",
        "                for k in range(1, x_g.shape[0]):\n",
        "                    if visibility[k] > self.prob_th:\n",
        "                        im_ipm = cv2.line(im_ipm, (x_ipm[k - 1], y_ipm[k - 1]),\n",
        "                                          (x_ipm[k], y_ipm[k]), color, width)\n",
        "                    else:\n",
        "                        im_ipm = cv2.line(im_ipm, (x_ipm[k - 1], y_ipm[k - 1]),\n",
        "                                          (x_ipm[k], y_ipm[k]), [0, 0, 0], width)\n",
        "        return im_ipm\n",
        "\n",
        "    def draw_3d_curves(self, ax, lane_anchor, draw_type='laneline', color=[0, 0, 1]):\n",
        "        for j in range(lane_anchor.shape[0]):\n",
        "            # draw laneline\n",
        "            if draw_type is 'laneline' and lane_anchor[j, self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, :self.num_y_steps]\n",
        "                x_g = x_offsets + self.anchor_x_steps[j]\n",
        "                if self.no_3d:\n",
        "                    z_g = np.zeros_like(x_g)\n",
        "                else:\n",
        "                    z_g = lane_anchor[j, self.num_y_steps:2*self.num_y_steps]\n",
        "                ax.plot(x_g, self.anchor_y_steps, z_g, color=color)\n",
        "\n",
        "            # draw centerline\n",
        "            if draw_type is 'centerline' and lane_anchor[j, 2*self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, self.anchor_dim:self.anchor_dim + self.num_y_steps]\n",
        "                x_g = x_offsets + self.anchor_x_steps[j]\n",
        "                if self.no_3d:\n",
        "                    z_g = np.zeros_like(x_g)\n",
        "                else:\n",
        "                    z_g = lane_anchor[j, self.anchor_dim + self.num_y_steps:self.anchor_dim + 2*self.num_y_steps]\n",
        "                ax.plot(x_g, self.anchor_y_steps, z_g, color=color)\n",
        "\n",
        "            # draw the additional centerline for the merging case\n",
        "            if draw_type is 'centerline' and lane_anchor[j, 3*self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, 2*self.anchor_dim:2*self.anchor_dim + self.num_y_steps]\n",
        "                x_g = x_offsets + self.anchor_x_steps[j]\n",
        "                if self.no_3d:\n",
        "                    z_g = np.zeros_like(x_g)\n",
        "                else:\n",
        "                    z_g = lane_anchor[j, 2*self.anchor_dim + self.num_y_steps:2*self.anchor_dim + 2*self.num_y_steps]\n",
        "                ax.plot(x_g, self.anchor_y_steps, z_g, color=color)\n",
        "\n",
        "    def draw_3d_curves_new(self, ax, lane_anchor, h_cam, draw_type='laneline', color=[0, 0, 1]):\n",
        "        for j in range(lane_anchor.shape[0]):\n",
        "            # draw laneline\n",
        "            if draw_type is 'laneline' and lane_anchor[j, self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, :self.num_y_steps]\n",
        "                x_gflat = x_offsets + self.anchor_x_steps[j]\n",
        "                if self.no_3d:\n",
        "                    z_g = np.zeros_like(x_gflat)\n",
        "                    visibility = np.ones_like(x_gflat)\n",
        "                else:\n",
        "                    z_g = lane_anchor[j, self.num_y_steps:2*self.num_y_steps]\n",
        "                    visibility = lane_anchor[j, 2*self.num_y_steps:3*self.num_y_steps]\n",
        "                x_gflat = x_gflat[np.where(visibility > self.prob_th)]\n",
        "                z_g = z_g[np.where(visibility > self.prob_th)]\n",
        "                if len(x_gflat) > 0:\n",
        "                    # transform lane detected in flat ground space to 3d ground space\n",
        "                    x_g, y_g = transform_lane_gflat2g(h_cam,\n",
        "                                                      x_gflat,\n",
        "                                                      self.anchor_y_steps[np.where(visibility > self.prob_th)],\n",
        "                                                      z_g)\n",
        "                    ax.plot(x_g, y_g, z_g, color=color)\n",
        "\n",
        "            # draw centerline\n",
        "            if draw_type is 'centerline' and lane_anchor[j, 2*self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, self.anchor_dim:self.anchor_dim + self.num_y_steps]\n",
        "                x_gflat = x_offsets + self.anchor_x_steps[j]\n",
        "                if self.no_3d:\n",
        "                    z_g = np.zeros_like(x_gflat)\n",
        "                    visibility = np.ones_like(x_gflat)\n",
        "                else:\n",
        "                    z_g = lane_anchor[j, self.anchor_dim + self.num_y_steps:self.anchor_dim + 2*self.num_y_steps]\n",
        "                    visibility = lane_anchor[j, self.anchor_dim + 2*self.num_y_steps:self.anchor_dim + 3*self.num_y_steps]\n",
        "                x_gflat = x_gflat[np.where(visibility > self.prob_th)]\n",
        "                z_g = z_g[np.where(visibility > self.prob_th)]\n",
        "                if len(x_gflat) > 0:\n",
        "                    # transform lane detected in flat ground space to 3d ground space\n",
        "                    x_g, y_g = transform_lane_gflat2g(h_cam,\n",
        "                                                      x_gflat,\n",
        "                                                      self.anchor_y_steps[np.where(visibility > self.prob_th)],\n",
        "                                                      z_g)\n",
        "                    ax.plot(x_g, y_g, z_g, color=color)\n",
        "\n",
        "            # draw the additional centerline for the merging case\n",
        "            if draw_type is 'centerline' and lane_anchor[j, 3*self.anchor_dim - 1] > self.prob_th:\n",
        "                x_offsets = lane_anchor[j, 2*self.anchor_dim:2*self.anchor_dim + self.num_y_steps]\n",
        "                x_gflat = x_offsets + self.anchor_x_steps[j]\n",
        "                if self.no_3d:\n",
        "                    z_g = np.zeros_like(x_gflat)\n",
        "                    visibility = np.ones_like(x_gflat)\n",
        "                else:\n",
        "                    z_g = lane_anchor[j, 2*self.anchor_dim + self.num_y_steps:2*self.anchor_dim + 2*self.num_y_steps]\n",
        "                    visibility = lane_anchor[j, 2*self.anchor_dim + 2*self.num_y_steps:2*self.anchor_dim + 3*self.num_y_steps]\n",
        "                x_gflat = x_gflat[np.where(visibility > self.prob_th)]\n",
        "                z_g = z_g[np.where(visibility > self.prob_th)]\n",
        "                if len(x_gflat) > 0:\n",
        "                    # transform lane detected in flat ground space to 3d ground space\n",
        "                    x_g, y_g = transform_lane_gflat2g(h_cam,\n",
        "                                                      x_gflat,\n",
        "                                                      self.anchor_y_steps[np.where(visibility > self.prob_th)],\n",
        "                                                      z_g)\n",
        "                    ax.plot(x_g, y_g, z_g, color=color)\n",
        "\n",
        "    def save_result(self, dataset, train_or_val, epoch, batch_i, idx, images, gt, pred, pred_cam_pitch, pred_cam_height, aug_mat=np.identity(3, dtype=np.float), evaluate=False):\n",
        "        if not dataset.data_aug:\n",
        "            aug_mat = np.repeat(np.expand_dims(aug_mat, axis=0), idx.shape[0], axis=0)\n",
        "\n",
        "        for i in range(idx.shape[0]):\n",
        "            # during training, only visualize the first sample of this batch\n",
        "            if i > 0 and not evaluate:\n",
        "                break\n",
        "            im = images.permute(0, 2, 3, 1).data.cpu().numpy()[i]\n",
        "            # the vgg_std and vgg_mean are for images in [0, 1] range\n",
        "            im = im * np.array(self.vgg_std)\n",
        "            im = im + np.array(self.vgg_mean)\n",
        "            im = np.clip(im, 0, 1)\n",
        "\n",
        "            gt_anchors = gt[i]\n",
        "            pred_anchors = pred[i]\n",
        "\n",
        "            # apply nms to avoid output directly neighbored lanes\n",
        "            # consider w/o centerline cases\n",
        "            if self.no_centerline:\n",
        "                pred_anchors[:, -1] = nms_1d(pred_anchors[:, -1])\n",
        "            else:\n",
        "                pred_anchors[:, self.anchor_dim - 1] = nms_1d(pred_anchors[:, self.anchor_dim - 1])\n",
        "                pred_anchors[:, 2 * self.anchor_dim - 1] = nms_1d(pred_anchors[:, 2 * self.anchor_dim - 1])\n",
        "                pred_anchors[:, 3 * self.anchor_dim - 1] = nms_1d(pred_anchors[:, 3 * self.anchor_dim - 1])\n",
        "\n",
        "            H_g2im, P_g2im, H_crop, H_im2ipm = dataset.transform_mats(idx[i])\n",
        "            if self.no_3d:\n",
        "                P_gt = np.matmul(H_crop, H_g2im)\n",
        "                H_g2im_pred = homograpthy_g2im(pred_cam_pitch[i],\n",
        "                                               pred_cam_height[i], dataset.K)\n",
        "                P_pred = np.matmul(H_crop, H_g2im_pred)\n",
        "\n",
        "                # consider data augmentation\n",
        "                P_gt = np.matmul(aug_mat[i, :, :], P_gt)\n",
        "                P_pred = np.matmul(aug_mat[i, :, :], P_pred)\n",
        "            else:\n",
        "                P_gt = np.matmul(H_crop, P_g2im)\n",
        "                P_g2im_pred = projection_g2im(pred_cam_pitch[i],\n",
        "                                              pred_cam_height[i], dataset.K)\n",
        "                P_pred = np.matmul(H_crop, P_g2im_pred)\n",
        "\n",
        "                # consider data augmentation\n",
        "                P_gt = np.matmul(aug_mat[i, :, :], P_gt)\n",
        "                P_pred = np.matmul(aug_mat[i, :, :], P_pred)\n",
        "\n",
        "            # update transformation with image augmentation\n",
        "            H_im2ipm = np.matmul(H_im2ipm, np.linalg.inv(aug_mat[i, :, :]))\n",
        "            im_ipm = cv2.warpPerspective(im, H_im2ipm, (self.ipm_w, self.ipm_h))\n",
        "            im_ipm = np.clip(im_ipm, 0, 1)\n",
        "\n",
        "            # draw lanes on image\n",
        "            im_laneline = im.copy()\n",
        "            im_laneline = self.draw_on_img(im_laneline, gt_anchors, P_gt, 'laneline', [0, 0, 1])\n",
        "            im_laneline = self.draw_on_img(im_laneline, pred_anchors, P_pred, 'laneline', [1, 0, 0])\n",
        "            if not self.no_centerline:\n",
        "                im_centerline = im.copy()\n",
        "                im_centerline = self.draw_on_img(im_centerline, gt_anchors, P_gt, 'centerline', [0, 0, 1])\n",
        "                im_centerline = self.draw_on_img(im_centerline, pred_anchors, P_pred, 'centerline', [1, 0, 0])\n",
        "\n",
        "            # draw lanes on ipm\n",
        "            ipm_laneline = im_ipm.copy()\n",
        "            ipm_laneline = self.draw_on_ipm(ipm_laneline, gt_anchors, 'laneline', [0, 0, 1])\n",
        "            ipm_laneline = self.draw_on_ipm(ipm_laneline, pred_anchors, 'laneline', [1, 0, 0])\n",
        "            if not self.no_centerline:\n",
        "                ipm_centerline = im_ipm.copy()\n",
        "                ipm_centerline = self.draw_on_ipm(ipm_centerline, gt_anchors, 'centerline', [0, 0, 1])\n",
        "                ipm_centerline = self.draw_on_ipm(ipm_centerline, pred_anchors, 'centerline', [1, 0, 0])\n",
        "\n",
        "            # plot on a single figure\n",
        "            if self.no_centerline and self.no_3d:\n",
        "                fig = plt.figure()\n",
        "                ax1 = fig.add_subplot(121)\n",
        "                ax2 = fig.add_subplot(122)\n",
        "                ax1.imshow(im_laneline)\n",
        "                ax2.imshow(ipm_laneline)\n",
        "            elif not self.no_centerline and self.no_3d:\n",
        "                fig = plt.figure()\n",
        "                ax1 = fig.add_subplot(221)\n",
        "                ax2 = fig.add_subplot(222)\n",
        "                ax3 = fig.add_subplot(223)\n",
        "                ax4 = fig.add_subplot(224)\n",
        "                ax1.imshow(im_laneline)\n",
        "                ax2.imshow(ipm_laneline)\n",
        "                ax3.imshow(im_centerline)\n",
        "                ax4.imshow(ipm_centerline)\n",
        "            elif not self.no_centerline and not self.no_3d:\n",
        "                fig = plt.figure()\n",
        "                ax1 = fig.add_subplot(231)\n",
        "                ax2 = fig.add_subplot(232)\n",
        "                ax3 = fig.add_subplot(233, projection='3d')\n",
        "                ax4 = fig.add_subplot(234)\n",
        "                ax5 = fig.add_subplot(235)\n",
        "                ax6 = fig.add_subplot(236, projection='3d')\n",
        "                ax1.imshow(im_laneline)\n",
        "                ax2.imshow(ipm_laneline)\n",
        "                self.draw_3d_curves(ax3, gt_anchors, 'laneline', [0, 0, 1])\n",
        "                self.draw_3d_curves(ax3, pred_anchors, 'laneline', [1, 0, 0])\n",
        "                ax3.set_xlabel('x axis')\n",
        "                ax3.set_ylabel('y axis')\n",
        "                ax3.set_zlabel('z axis')\n",
        "                bottom, top = ax3.get_zlim()\n",
        "                ax3.set_zlim(min(bottom, -1), max(top, 1))\n",
        "                ax3.set_xlim(-20, 20)\n",
        "                ax3.set_ylim(0, 100)\n",
        "                ax4.imshow(im_centerline)\n",
        "                ax5.imshow(ipm_centerline)\n",
        "                self.draw_3d_curves(ax6, gt_anchors, 'centerline', [0, 0, 1])\n",
        "                self.draw_3d_curves(ax6, pred_anchors, 'centerline', [1, 0, 0])\n",
        "                ax6.set_xlabel('x axis')\n",
        "                ax6.set_ylabel('y axis')\n",
        "                ax6.set_zlabel('z axis')\n",
        "                bottom, top = ax6.get_zlim()\n",
        "                ax6.set_zlim(min(bottom, -1), max(top, 1))\n",
        "                ax6.set_xlim(-20, 20)\n",
        "                ax6.set_ylim(0, 100)\n",
        "\n",
        "            if evaluate:\n",
        "                fig.savefig(self.save_path + '/example/' + self.vis_folder + '/infer_{}'.format(idx[i]))\n",
        "            else:\n",
        "                fig.savefig(self.save_path + '/example/{}/epoch-{}_batch-{}_idx-{}'.format(train_or_val,\n",
        "                                                                                           epoch, batch_i, idx[i]))\n",
        "            plt.clf()\n",
        "            plt.close(fig)\n",
        "\n",
        "    def save_result_new(self, dataset, train_or_val, epoch, batch_i, idx, images, gt, pred, pred_cam_pitch, pred_cam_height, aug_mat=np.identity(3, dtype=np.float), evaluate=False):\n",
        "        if not dataset.data_aug:\n",
        "            aug_mat = np.repeat(np.expand_dims(aug_mat, axis=0), idx.shape[0], axis=0)\n",
        "\n",
        "        for i in range(idx.shape[0]):\n",
        "            # during training, only visualize the first sample of this batch\n",
        "            if i > 0 and not evaluate:\n",
        "                break\n",
        "            im = images.permute(0, 2, 3, 1).data.cpu().numpy()[i]\n",
        "            # the vgg_std and vgg_mean are for images in [0, 1] range\n",
        "            im = im * np.array(self.vgg_std)\n",
        "            im = im + np.array(self.vgg_mean)\n",
        "            im = np.clip(im, 0, 1)\n",
        "\n",
        "            gt_anchors = gt[i]\n",
        "            pred_anchors = pred[i]\n",
        "\n",
        "            # apply nms to avoid output directly neighbored lanes\n",
        "            # consider w/o centerline cases\n",
        "            if self.no_centerline:\n",
        "                pred_anchors[:, -1] = nms_1d(pred_anchors[:, -1])\n",
        "            else:\n",
        "                pred_anchors[:, self.anchor_dim - 1] = nms_1d(pred_anchors[:, self.anchor_dim - 1])\n",
        "                pred_anchors[:, 2 * self.anchor_dim - 1] = nms_1d(pred_anchors[:, 2 * self.anchor_dim - 1])\n",
        "                pred_anchors[:, 3 * self.anchor_dim - 1] = nms_1d(pred_anchors[:, 3 * self.anchor_dim - 1])\n",
        "\n",
        "            H_g2im, P_g2im, H_crop, H_im2ipm = dataset.transform_mats(idx[i])\n",
        "            P_gt = np.matmul(H_crop, H_g2im)\n",
        "            H_g2im_pred = homograpthy_g2im(pred_cam_pitch[i],\n",
        "                                           pred_cam_height[i], dataset.K)\n",
        "            P_pred = np.matmul(H_crop, H_g2im_pred)\n",
        "\n",
        "            # consider data augmentation\n",
        "            P_gt = np.matmul(aug_mat[i, :, :], P_gt)\n",
        "            P_pred = np.matmul(aug_mat[i, :, :], P_pred)\n",
        "\n",
        "            # update transformation with image augmentation\n",
        "            H_im2ipm = np.matmul(H_im2ipm, np.linalg.inv(aug_mat[i, :, :]))\n",
        "            im_ipm = cv2.warpPerspective(im, H_im2ipm, (self.ipm_w, self.ipm_h))\n",
        "            im_ipm = np.clip(im_ipm, 0, 1)\n",
        "\n",
        "            # draw lanes on image\n",
        "            im_laneline = im.copy()\n",
        "            im_laneline = self.draw_on_img_new(im_laneline, gt_anchors, P_gt, 'laneline', [0, 0, 1])\n",
        "            im_laneline = self.draw_on_img_new(im_laneline, pred_anchors, P_pred, 'laneline', [1, 0, 0])\n",
        "            if not self.no_centerline:\n",
        "                im_centerline = im.copy()\n",
        "                im_centerline = self.draw_on_img_new(im_centerline, gt_anchors, P_gt, 'centerline', [0, 0, 1])\n",
        "                im_centerline = self.draw_on_img_new(im_centerline, pred_anchors, P_pred, 'centerline', [1, 0, 0])\n",
        "\n",
        "            # draw lanes on ipm\n",
        "            ipm_laneline = im_ipm.copy()\n",
        "            ipm_laneline = self.draw_on_ipm_new(ipm_laneline, gt_anchors, 'laneline', [0, 0, 1])\n",
        "            ipm_laneline = self.draw_on_ipm_new(ipm_laneline, pred_anchors, 'laneline', [1, 0, 0])\n",
        "            if not self.no_centerline:\n",
        "                ipm_centerline = im_ipm.copy()\n",
        "                ipm_centerline = self.draw_on_ipm_new(ipm_centerline, gt_anchors, 'centerline', [0, 0, 1])\n",
        "                ipm_centerline = self.draw_on_ipm_new(ipm_centerline, pred_anchors, 'centerline', [1, 0, 0])\n",
        "\n",
        "            # plot on a single figure\n",
        "            if self.no_centerline and self.no_3d:\n",
        "                fig = plt.figure()\n",
        "                ax1 = fig.add_subplot(121)\n",
        "                ax2 = fig.add_subplot(122)\n",
        "                ax1.imshow(im_laneline)\n",
        "                ax2.imshow(ipm_laneline)\n",
        "            elif not self.no_centerline and self.no_3d:\n",
        "                fig = plt.figure()\n",
        "                ax1 = fig.add_subplot(221)\n",
        "                ax2 = fig.add_subplot(222)\n",
        "                ax3 = fig.add_subplot(223)\n",
        "                ax4 = fig.add_subplot(224)\n",
        "                ax1.imshow(im_laneline)\n",
        "                ax2.imshow(ipm_laneline)\n",
        "                ax3.imshow(im_centerline)\n",
        "                ax4.imshow(ipm_centerline)\n",
        "            elif not self.no_centerline and not self.no_3d:\n",
        "                fig = plt.figure()\n",
        "                ax1 = fig.add_subplot(231)\n",
        "                ax2 = fig.add_subplot(232)\n",
        "                ax3 = fig.add_subplot(233, projection='3d')\n",
        "                ax4 = fig.add_subplot(234)\n",
        "                ax5 = fig.add_subplot(235)\n",
        "                ax6 = fig.add_subplot(236, projection='3d')\n",
        "                ax1.imshow(im_laneline)\n",
        "                ax2.imshow(ipm_laneline)\n",
        "                # TODO:use separate gt_cam_height when ready\n",
        "                self.draw_3d_curves_new(ax3, gt_anchors, pred_cam_height[i], 'laneline', [0, 0, 1])\n",
        "                self.draw_3d_curves_new(ax3, pred_anchors, pred_cam_height[i], 'laneline', [1, 0, 0])\n",
        "                ax3.set_xlabel('x axis')\n",
        "                ax3.set_ylabel('y axis')\n",
        "                ax3.set_zlabel('z axis')\n",
        "                bottom, top = ax3.get_zlim()\n",
        "                ax3.set_xlim(-20, 20)\n",
        "                ax3.set_ylim(0, 100)\n",
        "                ax3.set_zlim(min(bottom, -1), max(top, 1))\n",
        "                ax4.imshow(im_centerline)\n",
        "                ax5.imshow(ipm_centerline)\n",
        "                # TODO:use separate gt_cam_height when ready\n",
        "                self.draw_3d_curves_new(ax6, gt_anchors, pred_cam_height[i], 'centerline', [0, 0, 1])\n",
        "                self.draw_3d_curves_new(ax6, pred_anchors, pred_cam_height[i], 'centerline', [1, 0, 0])\n",
        "                ax6.set_xlabel('x axis')\n",
        "                ax6.set_ylabel('y axis')\n",
        "                ax6.set_zlabel('z axis')\n",
        "                bottom, top = ax6.get_zlim()\n",
        "                ax6.set_xlim(-20, 20)\n",
        "                ax6.set_ylim(0, 100)\n",
        "                ax6.set_zlim(min(bottom, -1), max(top, 1))\n",
        "\n",
        "            if evaluate:\n",
        "                fig.savefig(self.save_path + '/example/' + self.vis_folder + '/infer_{}'.format(idx[i]))\n",
        "            else:\n",
        "                fig.savefig(self.save_path + '/example/{}/epoch-{}_batch-{}_idx-{}'.format(train_or_val,\n",
        "                                                                                           epoch, batch_i, idx[i]))\n",
        "            plt.clf()\n",
        "            plt.close(fig)\n",
        "\n",
        "\n",
        "def prune_3d_lane_by_visibility(lane_3d, visibility):\n",
        "    lane_3d = lane_3d[visibility > 0, ...]\n",
        "    return lane_3d\n",
        "\n",
        "\n",
        "def prune_3d_lane_by_range(lane_3d, x_min, x_max):\n",
        "    # TODO: solve hard coded range later\n",
        "    # remove points with y out of range\n",
        "    # 3D label may miss super long straight-line with only two points: Not have to be 200, gt need a min-step\n",
        "    # 2D dataset requires this to rule out those points projected to ground, but out of meaningful range\n",
        "    lane_3d = lane_3d[np.logical_and(lane_3d[:, 1] > 0, lane_3d[:, 1] < 200), ...]\n",
        "\n",
        "    # remove lane points out of x range\n",
        "    lane_3d = lane_3d[np.logical_and(lane_3d[:, 0] > x_min,\n",
        "                                     lane_3d[:, 0] < x_max), ...]\n",
        "    return lane_3d\n",
        "\n",
        "\n",
        "def resample_laneline_in_y(input_lane, y_steps, out_vis=False):\n",
        "    \"\"\"\n",
        "        Interpolate x, z values at each anchor grid, including those beyond the range of input lnae y range\n",
        "    :param input_lane: N x 2 or N x 3 ndarray, one row for a point (x, y, z-optional).\n",
        "                       It requires y values of input lane in ascending order\n",
        "    :param y_steps: a vector of steps in y\n",
        "    :param out_vis: whether to output visibility indicator which only depends on input y range\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    # at least two points are included\n",
        "    assert(input_lane.shape[0] >= 2)\n",
        "\n",
        "    y_min = np.min(input_lane[:, 1])-5\n",
        "    y_max = np.max(input_lane[:, 1])+5\n",
        "\n",
        "    if input_lane.shape[1] < 3:\n",
        "        input_lane = np.concatenate([input_lane, np.zeros([input_lane.shape[0], 1], dtype=np.float32)], axis=1)\n",
        "\n",
        "    f_x = interp1d(input_lane[:, 1], input_lane[:, 0], fill_value=\"extrapolate\")\n",
        "    f_z = interp1d(input_lane[:, 1], input_lane[:, 2], fill_value=\"extrapolate\")\n",
        "\n",
        "    x_values = f_x(y_steps)\n",
        "    z_values = f_z(y_steps)\n",
        "\n",
        "    if out_vis:\n",
        "        output_visibility = np.logical_and(y_steps >= y_min, y_steps <= y_max)\n",
        "        return x_values, z_values, output_visibility.astype(np.float32) + 1e-9\n",
        "    return x_values, z_values\n",
        "\n",
        "\n",
        "def resample_laneline_in_y_with_vis(input_lane, y_steps, vis_vec):\n",
        "    \"\"\"\n",
        "        Interpolate x, z values at each anchor grid, including those beyond the range of input lnae y range\n",
        "    :param input_lane: N x 2 or N x 3 ndarray, one row for a point (x, y, z-optional).\n",
        "                       It requires y values of input lane in ascending order\n",
        "    :param y_steps: a vector of steps in y\n",
        "    :param out_vis: whether to output visibility indicator which only depends on input y range\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    # at least two points are included\n",
        "    assert(input_lane.shape[0] >= 2)\n",
        "\n",
        "    if input_lane.shape[1] < 3:\n",
        "        input_lane = np.concatenate([input_lane, np.zeros([input_lane.shape[0], 1], dtype=np.float32)], axis=1)\n",
        "\n",
        "    f_x = interp1d(input_lane[:, 1], input_lane[:, 0], fill_value=\"extrapolate\")\n",
        "    f_z = interp1d(input_lane[:, 1], input_lane[:, 2], fill_value=\"extrapolate\")\n",
        "    f_vis = interp1d(input_lane[:, 1], vis_vec, fill_value=\"extrapolate\")\n",
        "\n",
        "    x_values = f_x(y_steps)\n",
        "    z_values = f_z(y_steps)\n",
        "    vis_values = f_vis(y_steps)\n",
        "\n",
        "    x_values = x_values[vis_values > 0.5]\n",
        "    y_values = y_steps[vis_values > 0.5]\n",
        "    z_values = z_values[vis_values > 0.5]\n",
        "    return np.array([x_values, y_values, z_values]).T\n",
        "\n",
        "\n",
        "def homography_im2ipm_norm(top_view_region, org_img_size, crop_y, resize_img_size, cam_pitch, cam_height, K):\n",
        "    \"\"\"\n",
        "        Compute the normalized transformation such that image region are mapped to top_view region maps to\n",
        "        the top view image's 4 corners\n",
        "        Ground coordinates: x-right, y-forward, z-up\n",
        "        The purpose of applying normalized transformation: 1. invariance in scale change\n",
        "                                                           2.Torch grid sample is based on normalized grids\n",
        "    :param top_view_region: a 4 X 2 list of (X, Y) indicating the top-view region corners in order:\n",
        "                            top-left, top-right, bottom-left, bottom-right\n",
        "    :param org_img_size: the size of original image size: [h, w]\n",
        "    :param crop_y: pixels croped from original img\n",
        "    :param resize_img_size: the size of image as network input: [h, w]\n",
        "    :param cam_pitch: camera pitch angle wrt ground plane\n",
        "    :param cam_height: camera height wrt ground plane in meters\n",
        "    :param K: camera intrinsic parameters\n",
        "    :return: H_im2ipm_norm: the normalized transformation from image to IPM image\n",
        "    \"\"\"\n",
        "\n",
        "    # compute homography transformation from ground to image (only this depends on cam_pitch and cam height)\n",
        "    H_g2im = homograpthy_g2im(cam_pitch, cam_height, K)\n",
        "    # transform original image region to network input region\n",
        "    H_c = homography_crop_resize(org_img_size, crop_y, resize_img_size)\n",
        "    H_g2im = np.matmul(H_c, H_g2im)\n",
        "\n",
        "    # compute top-view corners' coordinates in image\n",
        "    x_2d, y_2d = homographic_transformation(H_g2im, top_view_region[:, 0], top_view_region[:, 1])\n",
        "    border_im = np.concatenate([x_2d.reshape(-1, 1), y_2d.reshape(-1, 1)], axis=1)\n",
        "\n",
        "    # compute the normalized transformation\n",
        "    border_im[:, 0] = border_im[:, 0] / resize_img_size[1]\n",
        "    border_im[:, 1] = border_im[:, 1] / resize_img_size[0]\n",
        "    border_im = np.float32(border_im)\n",
        "    dst = np.float32([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
        "    # img to ipm\n",
        "    H_im2ipm_norm = cv2.getPerspectiveTransform(border_im, dst)\n",
        "    # ipm to im\n",
        "    H_ipm2im_norm = cv2.getPerspectiveTransform(dst, border_im)\n",
        "    return H_im2ipm_norm, H_ipm2im_norm\n",
        "\n",
        "\n",
        "def homography_ipmnorm2g(top_view_region):\n",
        "    src = np.float32([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
        "    H_ipmnorm2g = cv2.getPerspectiveTransform(src, np.float32(top_view_region))\n",
        "    return H_ipmnorm2g\n",
        "\n",
        "\n",
        "def homograpthy_g2im(cam_pitch, cam_height, K):\n",
        "    # transform top-view region to original image region\n",
        "    R_g2c = np.array([[1, 0, 0],\n",
        "                      [0, np.cos(np.pi / 2 + cam_pitch), -np.sin(np.pi / 2 + cam_pitch)],\n",
        "                      [0, np.sin(np.pi / 2 + cam_pitch), np.cos(np.pi / 2 + cam_pitch)]])\n",
        "    H_g2im = np.matmul(K, np.concatenate([R_g2c[:, 0:2], [[0], [cam_height], [0]]], 1))\n",
        "    return H_g2im\n",
        "\n",
        "\n",
        "def projection_g2im(cam_pitch, cam_height, K):\n",
        "    P_g2c = np.array([[1,                             0,                              0,          0],\n",
        "                      [0, np.cos(np.pi / 2 + cam_pitch), -np.sin(np.pi / 2 + cam_pitch), cam_height],\n",
        "                      [0, np.sin(np.pi / 2 + cam_pitch),  np.cos(np.pi / 2 + cam_pitch),          0]])\n",
        "    P_g2im = np.matmul(K, P_g2c)\n",
        "    return P_g2im\n",
        "\n",
        "\n",
        "def homography_crop_resize(org_img_size, crop_y, resize_img_size):\n",
        "    \"\"\"\n",
        "        compute the homography matrix transform original image to cropped and resized image\n",
        "    :param org_img_size: [org_h, org_w]\n",
        "    :param crop_y:\n",
        "    :param resize_img_size: [resize_h, resize_w]\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # transform original image region to network input region\n",
        "    ratio_x = resize_img_size[1] / org_img_size[1]\n",
        "    ratio_y = resize_img_size[0] / (org_img_size[0] - crop_y)\n",
        "    H_c = np.array([[ratio_x, 0, 0],\n",
        "                    [0, ratio_y, -ratio_y*crop_y],\n",
        "                    [0, 0, 1]])\n",
        "    return H_c\n",
        "\n",
        "\n",
        "def homographic_transformation(Matrix, x, y):\n",
        "    \"\"\"\n",
        "    Helper function to transform coordinates defined by transformation matrix\n",
        "    Args:\n",
        "            Matrix (multi dim - array): 3x3 homography matrix\n",
        "            x (array): original x coordinates\n",
        "            y (array): original y coordinates\n",
        "    \"\"\"\n",
        "    ones = np.ones((1, len(y)))\n",
        "    coordinates = np.vstack((x, y, ones))\n",
        "    trans = np.matmul(Matrix, coordinates)\n",
        "\n",
        "    x_vals = trans[0, :]/trans[2, :]\n",
        "    y_vals = trans[1, :]/trans[2, :]\n",
        "    return x_vals, y_vals\n",
        "\n",
        "\n",
        "def projective_transformation(Matrix, x, y, z):\n",
        "    \"\"\"\n",
        "    Helper function to transform coordinates defined by transformation matrix\n",
        "    Args:\n",
        "            Matrix (multi dim - array): 3x4 projection matrix\n",
        "            x (array): original x coordinates\n",
        "            y (array): original y coordinates\n",
        "            z (array): original z coordinates\n",
        "    \"\"\"\n",
        "    ones = np.ones((1, len(z)))\n",
        "    coordinates = np.vstack((x, y, z, ones))\n",
        "    trans = np.matmul(Matrix, coordinates)\n",
        "\n",
        "    x_vals = trans[0, :]/trans[2, :]\n",
        "    y_vals = trans[1, :]/trans[2, :]\n",
        "    return x_vals, y_vals\n",
        "\n",
        "\n",
        "def transform_lane_gflat2g(h_cam, X_gflat, Y_gflat, Z_g):\n",
        "    \"\"\"\n",
        "        Given X coordinates in flat ground space, Y coordinates in flat ground space, and Z coordinates in real 3D ground space\n",
        "        with projection matrix from 3D ground to flat ground, compute real 3D coordinates X, Y in 3D ground space.\n",
        "    :param P_g2gflat: a 3 X 4 matrix transforms lane form 3d ground x,y,z to flat ground x, y\n",
        "    :param X_gflat: X coordinates in flat ground space\n",
        "    :param Y_gflat: Y coordinates in flat ground space\n",
        "    :param Z_g: Z coordinates in real 3D ground space\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    X_g = X_gflat - X_gflat * Z_g / h_cam\n",
        "    Y_g = Y_gflat - Y_gflat * Z_g / h_cam\n",
        "\n",
        "    return X_g, Y_g\n",
        "\n",
        "\n",
        "def transform_lane_g2gflat(h_cam, X_g, Y_g, Z_g):\n",
        "    \"\"\"\n",
        "        Given X coordinates in flat ground space, Y coordinates in flat ground space, and Z coordinates in real 3D ground space\n",
        "        with projection matrix from 3D ground to flat ground, compute real 3D coordinates X, Y in 3D ground space.\n",
        "    :param P_g2gflat: a 3 X 4 matrix transforms lane form 3d ground x,y,z to flat ground x, y\n",
        "    :param X_gflat: X coordinates in flat ground space\n",
        "    :param Y_gflat: Y coordinates in flat ground space\n",
        "    :param Z_g: Z coordinates in real 3D ground space\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    X_gflat = X_g * h_cam / (h_cam - Z_g)\n",
        "    Y_gflat = Y_g * h_cam / (h_cam - Z_g)\n",
        "\n",
        "    return X_gflat, Y_gflat\n",
        "\n",
        "\n",
        "def nms_1d(v):\n",
        "    \"\"\"\n",
        "    :param v: a 1D numpy array\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    v_out = v.copy()\n",
        "    len = v.shape[0]\n",
        "    if len < 2:\n",
        "        return v\n",
        "    for i in range(len):\n",
        "        if i is not 0 and v[i - 1] > v[i]:\n",
        "            v_out[i] = 0.\n",
        "        elif i is not len-1 and v[i+1] > v[i]:\n",
        "            v_out[i] = 0.\n",
        "    return v_out\n",
        "\n",
        "\n",
        "def first_run(save_path):\n",
        "    txt_file = os.path.join(save_path,'first_run.txt')\n",
        "    if not os.path.exists(txt_file):\n",
        "        open(txt_file, 'w').close()\n",
        "    else:\n",
        "        saved_epoch = open(txt_file).read()\n",
        "        if saved_epoch is None:\n",
        "            print('You forgot to delete [first run file]')\n",
        "            return '' \n",
        "        return saved_epoch\n",
        "    return ''\n",
        "\n",
        "\n",
        "def mkdir_if_missing(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        try:\n",
        "            os.makedirs(directory)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise\n",
        "\n",
        "\n",
        "# trick from stackoverflow\n",
        "def str2bool(argument):\n",
        "    if argument.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "        return True\n",
        "    elif argument.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "        return False\n",
        "    else:\n",
        "        raise argparse.ArgumentTypeError('Wrong argument in argparse, should be a boolean')\n",
        "\n",
        "\n",
        "class Logger(object):\n",
        "    \"\"\"\n",
        "    Source https://github.com/Cysu/open-reid/blob/master/reid/utils/logging.py.\n",
        "    \"\"\"\n",
        "    def __init__(self, fpath=None):\n",
        "        self.console = sys.stdout\n",
        "        self.file = None\n",
        "        self.fpath = fpath\n",
        "        if fpath is not None:\n",
        "            mkdir_if_missing(os.path.dirname(fpath))\n",
        "            self.file = open(fpath, 'w')\n",
        "\n",
        "    def __del__(self):\n",
        "        self.close()\n",
        "\n",
        "    def __enter__(self):\n",
        "        pass\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        self.close()\n",
        "\n",
        "    def write(self, msg):\n",
        "        self.console.write(msg)\n",
        "        if self.file is not None:\n",
        "            self.file.write(msg)\n",
        "\n",
        "    def flush(self):\n",
        "        self.console.flush()\n",
        "        if self.file is not None:\n",
        "            self.file.flush()\n",
        "            os.fsync(self.file.fileno())\n",
        "\n",
        "    def close(self):\n",
        "        self.console.close()\n",
        "        if self.file is not None:\n",
        "            self.file.close()\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def define_optim(optim, params, lr, weight_decay):\n",
        "    if optim == 'adam':\n",
        "        optimizer = torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
        "    elif optim == 'sgd':\n",
        "        optimizer = torch.optim.SGD(params, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "    elif optim == 'rmsprop':\n",
        "        optimizer = torch.optim.RMSprop(params, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "    else:\n",
        "        raise KeyError(\"The requested optimizer: {} is not implemented\".format(optim))\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def define_scheduler(optimizer, args):\n",
        "    if args.lr_policy == 'lambda':\n",
        "        def lambda_rule(epoch):\n",
        "            lr_l = 1.0 - max(0, epoch + 1 - args.niter) / float(args.niter_decay + 1)\n",
        "            return lr_l\n",
        "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
        "    elif args.lr_policy == 'step':\n",
        "        scheduler = lr_scheduler.StepLR(optimizer,\n",
        "                                        step_size=args.lr_decay_iters, gamma=args.gamma)\n",
        "    elif args.lr_policy == 'plateau':\n",
        "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                   factor=args.gamma,\n",
        "                                                   threshold=0.0001,\n",
        "                                                   patience=args.lr_decay_iters)\n",
        "    elif args.lr_policy == 'none':\n",
        "        scheduler = None\n",
        "    else:\n",
        "        return NotImplementedError('learning rate policy [%s] is not implemented', args.lr_policy)\n",
        "    return scheduler\n",
        "\n",
        "\n",
        "def define_init_weights(model, init_w='normal', activation='relu'):\n",
        "    print('Init weights in network with [{}]'.format(init_w))\n",
        "    if init_w == 'normal':\n",
        "        model.apply(weights_init_normal)\n",
        "    elif init_w == 'xavier':\n",
        "        model.apply(weights_init_xavier)\n",
        "    elif init_w == 'kaiming':\n",
        "        model.apply(weights_init_kaiming)\n",
        "    elif init_w == 'orthogonal':\n",
        "        model.apply(weights_init_orthogonal)\n",
        "    else:\n",
        "        raise NotImplementedError('initialization method [{}] is not implemented'.format(init_w))\n",
        "\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "#    print(classname)\n",
        "    if classname.find('Conv') != -1 or classname.find('ConvTranspose') != -1:\n",
        "        init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "    elif classname.find('Linear') != -1:\n",
        "        init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "def weights_init_xavier(m):\n",
        "    classname = m.__class__.__name__\n",
        "    # print(classname)\n",
        "    if classname.find('Conv') != -1 or classname.find('ConvTranspose') != -1:\n",
        "        init.xavier_normal_(m.weight.data, gain=0.02)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "    elif classname.find('Linear') != -1:\n",
        "        init.xavier_normal_(m.weight.data, gain=0.02)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "def weights_init_kaiming(m):\n",
        "    classname = m.__class__.__name__\n",
        "    # print(classname)\n",
        "    if classname.find('Conv') != -1 or classname.find('ConvTranspose') != -1:\n",
        "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "    elif classname.find('Linear') != -1:\n",
        "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "def weights_init_orthogonal(m):\n",
        "    classname = m.__class__.__name__\n",
        "#    print(classname)\n",
        "    if classname.find('Conv') != -1 or classname.find('ConvTranspose') != -1:\n",
        "        init.orthogonal(m.weight.data, gain=1)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "    elif classname.find('Linear') != -1:\n",
        "        init.orthogonal(m.weight.data, gain=1)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        init.constant_(m.bias.data, 0.0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKtvRoHwhwE3"
      },
      "source": [
        "\"\"\"\n",
        "MinCostFow solver adapted for matching two set of contours. The implementation is based on google-ortools.\n",
        "Author: Yuliang Guo (33yuliangguo@gmail.com)\n",
        "Date: March, 2020\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "from ortools.graph import pywrapgraph\n",
        "import time\n",
        "\n",
        "\n",
        "def SolveMinCostFlow(adj_mat, cost_mat):\n",
        "    \"\"\"\n",
        "        Solving an Assignment Problem with MinCostFlow\"\n",
        "    :param adj_mat: adjacency matrix with binary values indicating possible matchings between two sets\n",
        "    :param cost_mat: cost matrix recording the matching cost of every possible pair of items from two sets\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    # Instantiate a SimpleMinCostFlow solver.\n",
        "    min_cost_flow = pywrapgraph.SimpleMinCostFlow()\n",
        "    # Define the directed graph for the flow.\n",
        "\n",
        "    cnt_1, cnt_2 = adj_mat.shape\n",
        "    cnt_nonzero_row = int(np.sum(np.sum(adj_mat, axis=1) > 0))\n",
        "    cnt_nonzero_col = int(np.sum(np.sum(adj_mat, axis=0) > 0))\n",
        "\n",
        "    # prepare directed graph for the flow\n",
        "    start_nodes = np.zeros(cnt_1, dtype=np.int).tolist() +\\\n",
        "                  np.repeat(np.array(range(1, cnt_1+1)), cnt_2).tolist() + \\\n",
        "                  [i for i in range(cnt_1+1, cnt_1 + cnt_2 + 1)]\n",
        "    end_nodes = [i for i in range(1, cnt_1+1)] + \\\n",
        "                np.repeat(np.array([i for i in range(cnt_1+1, cnt_1 + cnt_2 + 1)]).reshape([1, -1]), cnt_1, axis=0).flatten().tolist() + \\\n",
        "                [cnt_1 + cnt_2 + 1 for i in range(cnt_2)]\n",
        "    capacities = np.ones(cnt_1, dtype=np.int).tolist() + adj_mat.flatten().astype(np.int).tolist() + np.ones(cnt_2, dtype=np.int).tolist()\n",
        "    costs = (np.zeros(cnt_1, dtype=np.int).tolist() + cost_mat.flatten().astype(np.int).tolist() + np.zeros(cnt_2, dtype=np.int).tolist())\n",
        "    # Define an array of supplies at each node.\n",
        "    supplies = [min(cnt_nonzero_row, cnt_nonzero_col)] + np.zeros(cnt_1 + cnt_2, dtype=np.int).tolist() + [-min(cnt_nonzero_row, cnt_nonzero_col)]\n",
        "    # supplies = [min(cnt_1, cnt_2)] + np.zeros(cnt_1 + cnt_2, dtype=np.int).tolist() + [-min(cnt_1, cnt_2)]\n",
        "    source = 0\n",
        "    sink = cnt_1 + cnt_2 + 1\n",
        "\n",
        "    # Add each arc.\n",
        "    for i in range(len(start_nodes)):\n",
        "        min_cost_flow.AddArcWithCapacityAndUnitCost(start_nodes[i], end_nodes[i],\n",
        "                                                    capacities[i], costs[i])\n",
        "\n",
        "    # Add node supplies.\n",
        "    for i in range(len(supplies)):\n",
        "        min_cost_flow.SetNodeSupply(i, supplies[i])\n",
        "\n",
        "    match_results = []\n",
        "    # Find the minimum cost flow between node 0 and node 10.\n",
        "    if min_cost_flow.Solve() == min_cost_flow.OPTIMAL:\n",
        "        # print('Total cost = ', min_cost_flow.OptimalCost())\n",
        "        # print()\n",
        "        for arc in range(min_cost_flow.NumArcs()):\n",
        "\n",
        "            # Can ignore arcs leading out of source or into sink.\n",
        "            if min_cost_flow.Tail(arc)!=source and min_cost_flow.Head(arc)!=sink:\n",
        "\n",
        "                # Arcs in the solution have a flow value of 1. Their start and end nodes\n",
        "                # give an assignment of worker to task.\n",
        "\n",
        "                if min_cost_flow.Flow(arc) > 0:\n",
        "                    # print('set A item %d assigned to set B item %d.  Cost = %d' % (\n",
        "                    #     min_cost_flow.Tail(arc)-1,\n",
        "                    #     min_cost_flow.Head(arc)-cnt_1-1,\n",
        "                    #     min_cost_flow.UnitCost(arc)))\n",
        "                    match_results.append([min_cost_flow.Tail(arc)-1,\n",
        "                                          min_cost_flow.Head(arc)-cnt_1-1,\n",
        "                                          min_cost_flow.UnitCost(arc)])\n",
        "    else:\n",
        "        print('There was an issue with the min cost flow input.')\n",
        "\n",
        "    return match_results\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Solving an Assignment Problem with MinCostFlow\"\"\"\n",
        "\n",
        "    # Instantiate a SimpleMinCostFlow solver.\n",
        "    min_cost_flow = pywrapgraph.SimpleMinCostFlow()\n",
        "    # Define the directed graph for the flow.\n",
        "\n",
        "    start_nodes = [0, 0, 0, 0] + [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4] + [5, 6, 7, 8]\n",
        "    end_nodes = [1, 2, 3, 4] + [5, 6, 7, 8, 5, 6, 7, 8, 5, 6, 7, 8, 5, 6, 7, 8] + [9, 9, 9, 9]\n",
        "    capacities = [1, 1, 1, 1] + [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] + [1, 1, 1, 1]\n",
        "    costs = ([0, 0, 0, 0] + [90, 76, 75, 70, 35, 85, 55, 65, 125, 95, 90, 105, 45, 110, 95, 115] + [0, 0, 0, 0])\n",
        "    # Define an array of supplies at each node.\n",
        "    supplies = [4, 0, 0, 0, 0, 0, 0, 0, 0, -4]\n",
        "    source = 0\n",
        "    sink = 9\n",
        "    tasks = 4\n",
        "\n",
        "    # Add each arc.\n",
        "    for i in range(len(start_nodes)):\n",
        "        min_cost_flow.AddArcWithCapacityAndUnitCost(start_nodes[i], end_nodes[i],\n",
        "                                                    capacities[i], costs[i])\n",
        "\n",
        "    # Add node supplies.\n",
        "\n",
        "    for i in range(len(supplies)):\n",
        "        min_cost_flow.SetNodeSupply(i, supplies[i])\n",
        "    # Find the minimum cost flow between node 0 and node 10.\n",
        "    if min_cost_flow.Solve() == min_cost_flow.OPTIMAL:\n",
        "        print('Total cost = ', min_cost_flow.OptimalCost())\n",
        "        print()\n",
        "        for arc in range(min_cost_flow.NumArcs()):\n",
        "\n",
        "            # Can ignore arcs leading out of source or into sink.\n",
        "            if min_cost_flow.Tail(arc)!=source and min_cost_flow.Head(arc)!=sink:\n",
        "\n",
        "                # Arcs in the solution have a flow value of 1. Their start and end nodes\n",
        "                # give an assignment of worker to task.\n",
        "\n",
        "                if min_cost_flow.Flow(arc) > 0:\n",
        "                    print('Worker %d assigned to task %d.  Cost = %d' % (\n",
        "                        min_cost_flow.Tail(arc),\n",
        "                        min_cost_flow.Head(arc),\n",
        "                        min_cost_flow.UnitCost(arc)))\n",
        "    else:\n",
        "        print('There was an issue with the min cost flow input.')\n",
        "\n",
        "'''\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.clock()\n",
        "    main()\n",
        "    print()\n",
        "    print(\"Time =\", time.clock() - start_time, \"seconds\")\n",
        "    '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEmtbMDZee_N"
      },
      "source": [
        "\"\"\"\n",
        "Description: This code is to evaluate 3D lane detection. The optimal matching between ground-truth set and predicted\n",
        "set of lanes are sought via solving a min cost flow.\n",
        "Evaluation metrics includes:\n",
        "    Average Precision (AP)\n",
        "    Max F-scores\n",
        "    x error close (0 - 40 m)\n",
        "    x error far (0 - 100 m)\n",
        "    z error close (0 - 40 m)\n",
        "    z error far (0 - 100 m)\n",
        "Reference: \"Gen-LaneNet: Generalized and Scalable Approach for 3D Lane Detection\". Y. Guo. etal. 2020\n",
        "Author: Yuliang Guo (33yuliangguo@gmail.com)\n",
        "Date: March, 2020\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import os.path as ops\n",
        "import copy\n",
        "import math\n",
        "import ujson as json\n",
        "from scipy.interpolate import interp1d\n",
        "import matplotlib\n",
        "#from tools.utils import *\n",
        "#from tools.MinCostFlow import SolveMinCostFlow\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (35, 30)\n",
        "plt.rcParams.update({'font.size': 25})\n",
        "plt.rcParams.update({'font.weight': 'semibold'})\n",
        "\n",
        "color = [[0, 0, 255],  # red\n",
        "         [0, 255, 0],  # green\n",
        "         [255, 0, 255],  # purple\n",
        "         [255, 255, 0]]  # cyan\n",
        "\n",
        "vis_min_y = 5\n",
        "vis_max_y = 80\n",
        "\n",
        "\n",
        "class LaneEval(object):\n",
        "    def __init__(self, args):\n",
        "        self.dataset_dir = args.dataset_dir\n",
        "        self.K = args.K\n",
        "        self.no_centerline = args.no_centerline\n",
        "        self.resize_h = args.resize_h\n",
        "        self.resize_w = args.resize_w\n",
        "        self.H_crop = homography_crop_resize([args.org_h, args.org_w], args.crop_y, [args.resize_h, args.resize_w])\n",
        "\n",
        "        self.x_min = args.top_view_region[0, 0]\n",
        "        self.x_max = args.top_view_region[1, 0]\n",
        "        self.y_min = args.top_view_region[2, 1]\n",
        "        self.y_max = args.top_view_region[0, 1]\n",
        "        self.y_samples = np.linspace(self.y_min, self.y_max, num=100, endpoint=False)\n",
        "        # self.y_samples = np.linspace(min_y, max_y, num=100, endpoint=False)\n",
        "        self.dist_th = 1.5\n",
        "        self.ratio_th = 0.75\n",
        "        self.close_range = 40\n",
        "\n",
        "    def bench(self, pred_lanes, gt_lanes, gt_visibility, raw_file, gt_cam_height, gt_cam_pitch, vis, ax1, ax2):\n",
        "        \"\"\"\n",
        "            Matching predicted lanes and ground-truth lanes in their IPM projection, ignoring z attributes.\n",
        "            x error, y_error, and z error are all considered, although the matching does not rely on z\n",
        "            The input of prediction and ground-truth lanes are in ground coordinate, x-right, y-forward, z-up\n",
        "            The fundamental assumption is: 1. there are no two points from different lanes with identical x, y\n",
        "                                              but different z's\n",
        "                                           2. there are no two points from a single lane having identical x, y\n",
        "                                              but different z's\n",
        "            If the interest area is within the current drivable road, the above assumptions are almost always valid.\n",
        "        :param pred_lanes: N X 2 or N X 3 lists depending on 2D or 3D\n",
        "        :param gt_lanes: N X 2 or N X 3 lists depending on 2D or 3D\n",
        "        :param raw_file: file path rooted in dataset folder\n",
        "        :param gt_cam_height: camera height given in ground-truth data\n",
        "        :param gt_cam_pitch: camera pitch given in ground-truth data\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        # change this properly\n",
        "        close_range_idx = np.where(self.y_samples > self.close_range)[0][0]\n",
        "\n",
        "        r_lane, p_lane = 0., 0.\n",
        "        x_error_close = []\n",
        "        x_error_far = []\n",
        "        z_error_close = []\n",
        "        z_error_far = []\n",
        "\n",
        "        # only keep the visible portion\n",
        "        gt_lanes = [prune_3d_lane_by_visibility(np.array(gt_lane), np.array(gt_visibility[k])) for k, gt_lane in\n",
        "                    enumerate(gt_lanes)]\n",
        "        gt_lanes = [lane for lane in gt_lanes if lane.shape[0] > 1]\n",
        "        # only consider those gt lanes overlapping with sampling range\n",
        "        gt_lanes = [lane for lane in gt_lanes if lane[0, 1] < self.y_samples[-1] and lane[-1, 1] > self.y_samples[0]]\n",
        "        gt_lanes = [prune_3d_lane_by_range(np.array(gt_lane), 3 * self.x_min, 3 * self.x_max) for gt_lane in gt_lanes]\n",
        "        gt_lanes = [lane for lane in gt_lanes if lane.shape[0] > 1]\n",
        "        cnt_gt = len(gt_lanes)\n",
        "        cnt_pred = len(pred_lanes)\n",
        "\n",
        "        gt_visibility_mat = np.zeros((cnt_gt, 100))\n",
        "        pred_visibility_mat = np.zeros((cnt_pred, 100))\n",
        "        # resample gt and pred at y_samples\n",
        "        for i in range(cnt_gt):\n",
        "            min_y = np.min(np.array(gt_lanes[i])[:, 1])\n",
        "            max_y = np.max(np.array(gt_lanes[i])[:, 1])\n",
        "            x_values, z_values, visibility_vec = resample_laneline_in_y(np.array(gt_lanes[i]), self.y_samples,\n",
        "                                                                        out_vis=True)\n",
        "            gt_lanes[i] = np.vstack([x_values, z_values]).T\n",
        "            gt_visibility_mat[i, :] = np.logical_and(x_values >= self.x_min,\n",
        "                                                     np.logical_and(x_values <= self.x_max,\n",
        "                                                                    np.logical_and(self.y_samples >= min_y,\n",
        "                                                                                   self.y_samples <= max_y)))\n",
        "            gt_visibility_mat[i, :] = np.logical_and(gt_visibility_mat[i, :], visibility_vec)\n",
        "\n",
        "        for i in range(cnt_pred):\n",
        "            # # ATTENTION: ensure y mono increase before interpolation: but it can reduce size\n",
        "            # pred_lanes[i] = make_lane_y_mono_inc(np.array(pred_lanes[i]))\n",
        "            # pred_lane = prune_3d_lane_by_range(np.array(pred_lanes[i]), self.x_min, self.x_max)\n",
        "            min_y = np.min(np.array(pred_lanes[i])[:, 1])\n",
        "            max_y = np.max(np.array(pred_lanes[i])[:, 1])\n",
        "            x_values, z_values, visibility_vec = resample_laneline_in_y(np.array(pred_lanes[i]), self.y_samples,\n",
        "                                                                        out_vis=True)\n",
        "            pred_lanes[i] = np.vstack([x_values, z_values]).T\n",
        "            pred_visibility_mat[i, :] = np.logical_and(x_values >= self.x_min,\n",
        "                                                       np.logical_and(x_values <= self.x_max,\n",
        "                                                                      np.logical_and(self.y_samples >= min_y,\n",
        "                                                                                     self.y_samples <= max_y)))\n",
        "            pred_visibility_mat[i, :] = np.logical_and(pred_visibility_mat[i, :], visibility_vec)\n",
        "            # pred_visibility_mat[i, :] = np.logical_and(x_values >= self.x_min, x_values <= self.x_max)\n",
        "\n",
        "        adj_mat = np.zeros((cnt_gt, cnt_pred), dtype=np.int)\n",
        "        cost_mat = np.zeros((cnt_gt, cnt_pred), dtype=np.int)\n",
        "        cost_mat.fill(1000)\n",
        "        num_match_mat = np.zeros((cnt_gt, cnt_pred), dtype=np.float)\n",
        "        x_dist_mat_close = np.zeros((cnt_gt, cnt_pred), dtype=np.float)\n",
        "        x_dist_mat_close.fill(1000.)\n",
        "        x_dist_mat_far = np.zeros((cnt_gt, cnt_pred), dtype=np.float)\n",
        "        x_dist_mat_far.fill(1000.)\n",
        "        z_dist_mat_close = np.zeros((cnt_gt, cnt_pred), dtype=np.float)\n",
        "        z_dist_mat_close.fill(1000.)\n",
        "        z_dist_mat_far = np.zeros((cnt_gt, cnt_pred), dtype=np.float)\n",
        "        z_dist_mat_far.fill(1000.)\n",
        "        # compute curve to curve distance\n",
        "        for i in range(cnt_gt):\n",
        "            for j in range(cnt_pred):\n",
        "                x_dist = np.abs(gt_lanes[i][:, 0] - pred_lanes[j][:, 0])\n",
        "                z_dist = np.abs(gt_lanes[i][:, 1] - pred_lanes[j][:, 1])\n",
        "                euclidean_dist = np.sqrt(x_dist ** 2 + z_dist ** 2)\n",
        "\n",
        "                # apply visibility to penalize different partial matching accordingly\n",
        "                euclidean_dist[\n",
        "                    np.logical_or(gt_visibility_mat[i, :] < 0.5, pred_visibility_mat[j, :] < 0.5)] = self.dist_th\n",
        "\n",
        "                # if np.average(euclidean_dist) < 2*self.dist_th: # don't prune here to encourage finding perfect match\n",
        "                num_match_mat[i, j] = np.sum(euclidean_dist < self.dist_th)\n",
        "                adj_mat[i, j] = 1\n",
        "                # ATTENTION: use the sum as int type to meet the requirements of min cost flow optimization (int type)\n",
        "                # using num_match_mat as cost does not work?\n",
        "                cost_mat[i, j] = np.sum(euclidean_dist).astype(np.int)\n",
        "                # cost_mat[i, j] = num_match_mat[i, j]\n",
        "\n",
        "                # use the both visible portion to calculate distance error\n",
        "                both_visible_indices = np.logical_and(gt_visibility_mat[i, :] > 0.5, pred_visibility_mat[j, :] > 0.5)\n",
        "                if np.sum(both_visible_indices[:close_range_idx]) > 0:\n",
        "                    x_dist_mat_close[i, j] = np.sum(\n",
        "                        x_dist[:close_range_idx] * both_visible_indices[:close_range_idx]) / np.sum(\n",
        "                        both_visible_indices[:close_range_idx])\n",
        "                    z_dist_mat_close[i, j] = np.sum(\n",
        "                        z_dist[:close_range_idx] * both_visible_indices[:close_range_idx]) / np.sum(\n",
        "                        both_visible_indices[:close_range_idx])\n",
        "                else:\n",
        "                    x_dist_mat_close[i, j] = self.dist_th\n",
        "                    z_dist_mat_close[i, j] = self.dist_th\n",
        "\n",
        "                if np.sum(both_visible_indices[close_range_idx:]) > 0:\n",
        "                    x_dist_mat_far[i, j] = np.sum(\n",
        "                        x_dist[close_range_idx:] * both_visible_indices[close_range_idx:]) / np.sum(\n",
        "                        both_visible_indices[close_range_idx:])\n",
        "                    z_dist_mat_far[i, j] = np.sum(\n",
        "                        z_dist[close_range_idx:] * both_visible_indices[close_range_idx:]) / np.sum(\n",
        "                        both_visible_indices[close_range_idx:])\n",
        "                else:\n",
        "                    x_dist_mat_far[i, j] = self.dist_th\n",
        "                    z_dist_mat_far[i, j] = self.dist_th\n",
        "\n",
        "        # solve bipartite matching vis min cost flow solver\n",
        "        match_results = SolveMinCostFlow(adj_mat, cost_mat)\n",
        "        match_results = np.array(match_results)\n",
        "\n",
        "        # only a match with avg cost < self.dist_th is consider valid one\n",
        "        match_gt_ids = []\n",
        "        match_pred_ids = []\n",
        "        if match_results.shape[0] > 0:\n",
        "            for i in range(len(match_results)):\n",
        "                if match_results[i, 2] < self.dist_th * self.y_samples.shape[0]:\n",
        "                    gt_i = match_results[i, 0]\n",
        "                    pred_i = match_results[i, 1]\n",
        "                    # consider match when the matched points is above a ratio\n",
        "                    if num_match_mat[gt_i, pred_i] / np.sum(gt_visibility_mat[gt_i, :]) >= self.ratio_th:\n",
        "                        r_lane += 1\n",
        "                        match_gt_ids.append(gt_i)\n",
        "                    if num_match_mat[gt_i, pred_i] / np.sum(pred_visibility_mat[pred_i, :]) >= self.ratio_th:\n",
        "                        p_lane += 1\n",
        "                        match_pred_ids.append(pred_i)\n",
        "                    x_error_close.append(x_dist_mat_close[gt_i, pred_i])\n",
        "                    x_error_far.append(x_dist_mat_far[gt_i, pred_i])\n",
        "                    z_error_close.append(z_dist_mat_close[gt_i, pred_i])\n",
        "                    z_error_far.append(z_dist_mat_far[gt_i, pred_i])\n",
        "\n",
        "        # visualize lanelines and matching results both in image and 3D\n",
        "        if vis:\n",
        "            P_g2im = projection_g2im(gt_cam_pitch, gt_cam_height, self.K)\n",
        "            P_gt = np.matmul(self.H_crop, P_g2im)\n",
        "            img = cv2.imread(ops.join(self.dataset_dir, raw_file))\n",
        "            img = cv2.warpPerspective(img, self.H_crop, (self.resize_w, self.resize_h))\n",
        "            img = img.astype(np.float) / 255\n",
        "\n",
        "            for i in range(cnt_gt):\n",
        "                x_values = gt_lanes[i][:, 0]\n",
        "                z_values = gt_lanes[i][:, 1]\n",
        "                x_2d, y_2d = projective_transformation(P_gt, x_values, self.y_samples, z_values)\n",
        "                x_2d = x_2d.astype(np.int)\n",
        "                y_2d = y_2d.astype(np.int)\n",
        "\n",
        "                if i in match_gt_ids:\n",
        "                    color = [0, 0, 1]\n",
        "                else:\n",
        "                    color = [0, 1, 1]\n",
        "                for k in range(1, x_2d.shape[0]):\n",
        "                    # only draw the visible portion\n",
        "                    if gt_visibility_mat[i, k - 1] and gt_visibility_mat[i, k]:\n",
        "                        img = cv2.line(img, (x_2d[k - 1], y_2d[k - 1]), (x_2d[k], y_2d[k]), color[-1::-1], 3)\n",
        "                ax2.plot(x_values[np.where(gt_visibility_mat[i, :])],\n",
        "                         self.y_samples[np.where(gt_visibility_mat[i, :])],\n",
        "                         z_values[np.where(gt_visibility_mat[i, :])], color=color, linewidth=5)\n",
        "\n",
        "            for i in range(cnt_pred):\n",
        "                x_values = pred_lanes[i][:, 0]\n",
        "                z_values = pred_lanes[i][:, 1]\n",
        "                x_2d, y_2d = projective_transformation(P_gt, x_values, self.y_samples, z_values)\n",
        "                x_2d = x_2d.astype(np.int)\n",
        "                y_2d = y_2d.astype(np.int)\n",
        "\n",
        "                if i in match_pred_ids:\n",
        "                    color = [1, 0, 0]\n",
        "                else:\n",
        "                    color = [1, 0, 1]\n",
        "                for k in range(1, x_2d.shape[0]):\n",
        "                    # only draw the visible portion\n",
        "                    if pred_visibility_mat[i, k - 1] and pred_visibility_mat[i, k]:\n",
        "                        img = cv2.line(img, (x_2d[k - 1], y_2d[k - 1]), (x_2d[k], y_2d[k]), color[-1::-1], 2)\n",
        "                ax2.plot(x_values[np.where(pred_visibility_mat[i, :])],\n",
        "                         self.y_samples[np.where(pred_visibility_mat[i, :])],\n",
        "                         z_values[np.where(pred_visibility_mat[i, :])], color=color, linewidth=5)\n",
        "\n",
        "            cv2.putText(img, 'Recall: {:.3f}'.format(r_lane / (cnt_gt + 1e-6)),\n",
        "                        (5, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.7, color=(0, 0, 1), thickness=2)\n",
        "            cv2.putText(img, 'Precision: {:.3f}'.format(p_lane / (cnt_pred + 1e-6)),\n",
        "                        (5, 60), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.7, color=(0, 0, 1), thickness=2)\n",
        "            ax1.imshow(img[:, :, [2, 1, 0]])\n",
        "\n",
        "        return r_lane, p_lane, cnt_gt, cnt_pred, x_error_close, x_error_far, z_error_close, z_error_far\n",
        "\n",
        "    # compare predicted set and ground-truth set using a fixed lane probability threshold\n",
        "    def bench_one_submit(self, pred_file, gt_file, prob_th=0.5, vis=False):\n",
        "        if vis:\n",
        "            save_path = pred_file[:pred_file.rfind('/')]\n",
        "            save_path += '/vis'\n",
        "            if vis and not os.path.exists(save_path):\n",
        "                try:\n",
        "                    os.makedirs(save_path)\n",
        "                except OSError as e:\n",
        "                    print(e.message)\n",
        "        # try:\n",
        "        pred_lines = open(pred_file).readlines()\n",
        "        json_pred = [json.loads(line) for line in pred_lines]\n",
        "        # except BaseException as e:\n",
        "        #     raise Exception('Fail to load json file of the prediction.')\n",
        "        json_gt = [json.loads(line) for line in open(gt_file).readlines()]\n",
        "        if len(json_gt) != len(json_pred):\n",
        "            raise Exception('We do not get the predictions of all the test tasks')\n",
        "        gts = {l['raw_file']: l for l in json_gt}\n",
        "\n",
        "        laneline_stats = []\n",
        "        laneline_x_error_close = []\n",
        "        laneline_x_error_far = []\n",
        "        laneline_z_error_close = []\n",
        "        laneline_z_error_far = []\n",
        "        centerline_stats = []\n",
        "        centerline_x_error_close = []\n",
        "        centerline_x_error_far = []\n",
        "        centerline_z_error_close = []\n",
        "        centerline_z_error_far = []\n",
        "        for i, pred in enumerate(json_pred):\n",
        "            if 'raw_file' not in pred or 'laneLines' not in pred:\n",
        "                raise Exception('raw_file or lanelines not in some predictions.')\n",
        "            raw_file = pred['raw_file']\n",
        "\n",
        "            # if raw_file != 'images/05/0000347.jpg':\n",
        "            #     continue\n",
        "            pred_lanelines = pred['laneLines']\n",
        "            pred_laneLines_prob = pred['laneLines_prob']\n",
        "            pred_lanelines = [pred_lanelines[ii] for ii in range(len(pred_laneLines_prob)) if\n",
        "                              pred_laneLines_prob[ii] > prob_th]\n",
        "\n",
        "            if raw_file not in gts:\n",
        "                raise Exception('Some raw_file from your predictions do not exist in the test tasks.')\n",
        "            gt = gts[raw_file]\n",
        "            gt_cam_height = gt['cam_height']\n",
        "            gt_cam_pitch = gt['cam_pitch']\n",
        "\n",
        "            if vis:\n",
        "                fig = plt.figure()\n",
        "                ax1 = fig.add_subplot(221)\n",
        "                ax2 = fig.add_subplot(222, projection='3d')\n",
        "                ax3 = fig.add_subplot(223)\n",
        "                ax4 = fig.add_subplot(224, projection='3d')\n",
        "            else:\n",
        "                ax1 = 0\n",
        "                ax2 = 0\n",
        "                ax3 = 0\n",
        "                ax4 = 0\n",
        "\n",
        "            # evaluate lanelines\n",
        "            gt_lanelines = gt['laneLines']\n",
        "            gt_visibility = gt['laneLines_visibility']\n",
        "            # N to N matching of lanelines\n",
        "            r_lane, p_lane, cnt_gt, cnt_pred, \\\n",
        "            x_error_close, x_error_far, \\\n",
        "            z_error_close, z_error_far = self.bench(pred_lanelines,\n",
        "                                                    gt_lanelines,\n",
        "                                                    gt_visibility,\n",
        "                                                    raw_file,\n",
        "                                                    gt_cam_height,\n",
        "                                                    gt_cam_pitch,\n",
        "                                                    vis, ax1, ax2)\n",
        "            laneline_stats.append(np.array([r_lane, p_lane, cnt_gt, cnt_pred]))\n",
        "            # consider x_error z_error only for the matched lanes\n",
        "            # if r_lane > 0 and p_lane > 0:\n",
        "            laneline_x_error_close.extend(x_error_close)\n",
        "            laneline_x_error_far.extend(x_error_far)\n",
        "            laneline_z_error_close.extend(z_error_close)\n",
        "            laneline_z_error_far.extend(z_error_far)\n",
        "\n",
        "            # evaluate centerlines\n",
        "            if not self.no_centerline:\n",
        "                pred_centerlines = pred['centerLines']\n",
        "                pred_centerlines_prob = pred['centerLines_prob']\n",
        "                pred_centerlines = [pred_centerlines[ii] for ii in range(len(pred_centerlines_prob)) if\n",
        "                                    pred_centerlines_prob[ii] > prob_th]\n",
        "\n",
        "                gt_centerlines = gt['centerLines']\n",
        "                gt_visibility = gt['centerLines_visibility']\n",
        "\n",
        "                # N to N matching of lanelines\n",
        "                r_lane, p_lane, cnt_gt, cnt_pred, \\\n",
        "                x_error_close, x_error_far, \\\n",
        "                z_error_close, z_error_far = self.bench(pred_centerlines,\n",
        "                                                        gt_centerlines,\n",
        "                                                        gt_visibility,\n",
        "                                                        raw_file,\n",
        "                                                        gt_cam_height,\n",
        "                                                        gt_cam_pitch,\n",
        "                                                        vis, ax3, ax4)\n",
        "                centerline_stats.append(np.array([r_lane, p_lane, cnt_gt, cnt_pred]))\n",
        "                # consider x_error z_error only for the matched lanes\n",
        "                # if r_lane > 0 and p_lane > 0:\n",
        "                centerline_x_error_close.extend(x_error_close)\n",
        "                centerline_x_error_far.extend(x_error_far)\n",
        "                centerline_z_error_close.extend(z_error_close)\n",
        "                centerline_z_error_far.extend(z_error_far)\n",
        "\n",
        "            if vis:\n",
        "                ax1.set_xticks([])\n",
        "                ax1.set_yticks([])\n",
        "                # ax2.set_xlabel('x axis')\n",
        "                # ax2.set_ylabel('y axis')\n",
        "                # ax2.set_zlabel('z axis')\n",
        "                bottom, top = ax2.get_zlim()\n",
        "                left, right = ax2.get_xlim()\n",
        "                ax2.set_zlim(min(bottom, -0.1), max(top, 0.1))\n",
        "                ax2.set_xlim(left, right)\n",
        "                ax2.set_ylim(vis_min_y, vis_max_y)\n",
        "                ax2.locator_params(nbins=5, axis='x')\n",
        "                ax2.locator_params(nbins=5, axis='z')\n",
        "                ax2.tick_params(pad=18)\n",
        "\n",
        "                ax3.set_xticks([])\n",
        "                ax3.set_yticks([])\n",
        "                # ax4.set_xlabel('x axis')\n",
        "                # ax4.set_ylabel('y axis')\n",
        "                # ax4.set_zlabel('z axis')\n",
        "                bottom, top = ax4.get_zlim()\n",
        "                left, right = ax4.get_xlim()\n",
        "                ax4.set_zlim(min(bottom, -0.1), max(top, 0.1))\n",
        "                ax4.set_xlim(left, right)\n",
        "                ax4.set_ylim(vis_min_y, vis_max_y)\n",
        "                ax4.locator_params(nbins=5, axis='x')\n",
        "                ax4.locator_params(nbins=5, axis='z')\n",
        "                ax4.tick_params(pad=18)\n",
        "\n",
        "                fig.subplots_adjust(wspace=0, hspace=0.01)\n",
        "                fig.savefig(ops.join(save_path, raw_file.replace(\"/\", \"_\")))\n",
        "                plt.close(fig)\n",
        "                print('processed sample: {}  {}'.format(i, raw_file))\n",
        "\n",
        "        output_stats = []\n",
        "        laneline_stats = np.array(laneline_stats)\n",
        "        laneline_x_error_close = np.array(laneline_x_error_close)\n",
        "        laneline_x_error_far = np.array(laneline_x_error_far)\n",
        "        laneline_z_error_close = np.array(laneline_z_error_close)\n",
        "        laneline_z_error_far = np.array(laneline_z_error_far)\n",
        "\n",
        "        R_lane = np.sum(laneline_stats[:, 0]) / (np.sum(laneline_stats[:, 2]) + 1e-6)\n",
        "        P_lane = np.sum(laneline_stats[:, 1]) / (np.sum(laneline_stats[:, 3]) + 1e-6)\n",
        "        F_lane = 2 * R_lane * P_lane / (R_lane + P_lane + 1e-6)\n",
        "        x_error_close_avg = np.average(laneline_x_error_close)\n",
        "        x_error_far_avg = np.average(laneline_x_error_far)\n",
        "        z_error_close_avg = np.average(laneline_z_error_close)\n",
        "        z_error_far_avg = np.average(laneline_z_error_far)\n",
        "\n",
        "        output_stats.append(F_lane)\n",
        "        output_stats.append(R_lane)\n",
        "        output_stats.append(P_lane)\n",
        "        output_stats.append(x_error_close_avg)\n",
        "        output_stats.append(x_error_far_avg)\n",
        "        output_stats.append(z_error_close_avg)\n",
        "        output_stats.append(z_error_far_avg)\n",
        "\n",
        "        if not self.no_centerline:\n",
        "            centerline_stats = np.array(centerline_stats)\n",
        "            centerline_x_error_close = np.array(centerline_x_error_close)\n",
        "            centerline_x_error_far = np.array(centerline_x_error_far)\n",
        "            centerline_z_error_close = np.array(centerline_z_error_close)\n",
        "            centerline_z_error_far = np.array(centerline_z_error_far)\n",
        "\n",
        "            R_lane = np.sum(centerline_stats[:, 0]) / (np.sum(centerline_stats[:, 2]) + 1e-6)\n",
        "            P_lane = np.sum(centerline_stats[:, 1]) / (np.sum(centerline_stats[:, 3]) + 1e-6)\n",
        "            F_lane = 2 * R_lane * P_lane / (R_lane + P_lane + 1e-6)\n",
        "            x_error_close_avg = np.average(centerline_x_error_close)\n",
        "            x_error_far_avg = np.average(centerline_x_error_far)\n",
        "            z_error_close_avg = np.average(centerline_z_error_close)\n",
        "            z_error_far_avg = np.average(centerline_z_error_far)\n",
        "\n",
        "            output_stats.append(F_lane)\n",
        "            output_stats.append(R_lane)\n",
        "            output_stats.append(P_lane)\n",
        "            output_stats.append(x_error_close_avg)\n",
        "            output_stats.append(x_error_far_avg)\n",
        "            output_stats.append(z_error_close_avg)\n",
        "            output_stats.append(z_error_far_avg)\n",
        "\n",
        "        return output_stats\n",
        "\n",
        "    def bench_PR(self, pred_lanes, gt_lanes, gt_visibility):\n",
        "        \"\"\"\n",
        "            Matching predicted lanes and ground-truth lanes in their IPM projection, ignoring z attributes.\n",
        "            x error, y_error, and z error are all considered, although the matching does not rely on z\n",
        "            The input of prediction and ground-truth lanes are in ground coordinate, x-right, y-forward, z-up\n",
        "            The fundamental assumption is: 1. there are no two points from different lanes with identical x, y\n",
        "                                              but different z's\n",
        "                                           2. there are no two points from a single lane having identical x, y\n",
        "                                              but different z's\n",
        "            If the interest area is within the current drivable road, the above assumptions are almost always valid.\n",
        "        :param pred_lanes: N X 2 or N X 3 lists depending on 2D or 3D\n",
        "        :param gt_lanes: N X 2 or N X 3 lists depending on 2D or 3D\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        r_lane, p_lane = 0., 0.\n",
        "\n",
        "        # only keep the visible portion\n",
        "        gt_lanes = [prune_3d_lane_by_visibility(np.array(gt_lane), np.array(gt_visibility[k])) for k, gt_lane in\n",
        "                    enumerate(gt_lanes)]\n",
        "        gt_lanes = [lane for lane in gt_lanes if lane.shape[0] > 1]\n",
        "        # only consider those gt lanes overlapping with sampling range\n",
        "        gt_lanes = [lane for lane in gt_lanes if lane[0, 1] < self.y_samples[-1] and lane[-1, 1] > self.y_samples[0]]\n",
        "        gt_lanes = [prune_3d_lane_by_range(np.array(gt_lane), 3 * self.x_min, 3 * self.x_max) for gt_lane in gt_lanes]\n",
        "        gt_lanes = [lane for lane in gt_lanes if lane.shape[0] > 1]\n",
        "        cnt_gt = len(gt_lanes)\n",
        "        cnt_pred = len(pred_lanes)\n",
        "\n",
        "        gt_visibility_mat = np.zeros((cnt_gt, 100))\n",
        "        pred_visibility_mat = np.zeros((cnt_pred, 100))\n",
        "        # resample gt and pred at y_samples\n",
        "        for i in range(cnt_gt):\n",
        "            min_y = np.min(np.array(gt_lanes[i])[:, 1])\n",
        "            max_y = np.max(np.array(gt_lanes[i])[:, 1])\n",
        "            x_values, z_values, visibility_vec = resample_laneline_in_y(np.array(gt_lanes[i]), self.y_samples,\n",
        "                                                                        out_vis=True)\n",
        "            gt_lanes[i] = np.vstack([x_values, z_values]).T\n",
        "            gt_visibility_mat[i, :] = np.logical_and(x_values >= self.x_min,\n",
        "                                                     np.logical_and(x_values <= self.x_max,\n",
        "                                                                    np.logical_and(self.y_samples >= min_y,\n",
        "                                                                                   self.y_samples <= max_y)))\n",
        "            gt_visibility_mat[i, :] = np.logical_and(gt_visibility_mat[i, :], visibility_vec)\n",
        "\n",
        "        for i in range(cnt_pred):\n",
        "            # # ATTENTION: ensure y mono increase before interpolation: but it can reduce size\n",
        "            # pred_lanes[i] = make_lane_y_mono_inc(np.array(pred_lanes[i]))\n",
        "            # pred_lane = prune_3d_lane_by_range(np.array(pred_lanes[i]), self.x_min, self.x_max)\n",
        "            min_y = np.min(np.array(pred_lanes[i])[:, 1])\n",
        "            max_y = np.max(np.array(pred_lanes[i])[:, 1])\n",
        "            x_values, z_values, visibility_vec = resample_laneline_in_y(np.array(pred_lanes[i]), self.y_samples,\n",
        "                                                                        out_vis=True)\n",
        "            pred_lanes[i] = np.vstack([x_values, z_values]).T\n",
        "            pred_visibility_mat[i, :] = np.logical_and(x_values >= self.x_min,\n",
        "                                                       np.logical_and(x_values <= self.x_max,\n",
        "                                                                      np.logical_and(self.y_samples >= min_y,\n",
        "                                                                                     self.y_samples <= max_y)))\n",
        "            pred_visibility_mat[i, :] = np.logical_and(pred_visibility_mat[i, :], visibility_vec)\n",
        "            # pred_visibility_mat[i, :] = np.logical_and(x_values >= self.x_min, x_values <= self.x_max)\n",
        "\n",
        "        adj_mat = np.zeros((cnt_gt, cnt_pred), dtype=np.int)\n",
        "        cost_mat = np.zeros((cnt_gt, cnt_pred), dtype=np.int)\n",
        "        cost_mat.fill(1000)\n",
        "        num_match_mat = np.zeros((cnt_gt, cnt_pred), dtype=np.float)\n",
        "        # compute curve to curve distance\n",
        "        for i in range(cnt_gt):\n",
        "            for j in range(cnt_pred):\n",
        "                x_dist = np.abs(gt_lanes[i][:, 0] - pred_lanes[j][:, 0])\n",
        "                z_dist = np.abs(gt_lanes[i][:, 1] - pred_lanes[j][:, 1])\n",
        "                euclidean_dist = np.sqrt(x_dist ** 2 + z_dist ** 2)\n",
        "\n",
        "                # apply visibility to penalize different partial matching accordingly\n",
        "                euclidean_dist[\n",
        "                    np.logical_or(gt_visibility_mat[i, :] < 0.5, pred_visibility_mat[j, :] < 0.5)] = self.dist_th\n",
        "\n",
        "                # if np.average(euclidean_dist) < 2*self.dist_th: # don't prune here to encourage finding perfect match\n",
        "                num_match_mat[i, j] = np.sum(euclidean_dist < self.dist_th)\n",
        "                adj_mat[i, j] = 1\n",
        "                # ATTENTION: use the sum as int type to meet the requirements of min cost flow optimization (int type)\n",
        "                # why using num_match_mat as cost does not work?\n",
        "                cost_mat[i, j] = np.sum(euclidean_dist).astype(np.int)\n",
        "                # cost_mat[i, j] = num_match_mat[i, j]\n",
        "\n",
        "        # solve bipartite matching vis min cost flow solver\n",
        "        match_results = SolveMinCostFlow(adj_mat, cost_mat)\n",
        "        match_results = np.array(match_results)\n",
        "\n",
        "        # only a match with avg cost < self.dist_th is consider valid one\n",
        "        match_gt_ids = []\n",
        "        match_pred_ids = []\n",
        "        if match_results.shape[0] > 0:\n",
        "            for i in range(len(match_results)):\n",
        "                if match_results[i, 2] < self.dist_th * self.y_samples.shape[0]:\n",
        "                    gt_i = match_results[i, 0]\n",
        "                    pred_i = match_results[i, 1]\n",
        "                    # consider match when the matched points is above a ratio\n",
        "                    if num_match_mat[gt_i, pred_i] / np.sum(gt_visibility_mat[gt_i, :]) >= self.ratio_th:\n",
        "                        r_lane += 1\n",
        "                        match_gt_ids.append(gt_i)\n",
        "                    if num_match_mat[gt_i, pred_i] / np.sum(pred_visibility_mat[pred_i, :]) >= self.ratio_th:\n",
        "                        p_lane += 1\n",
        "                        match_pred_ids.append(pred_i)\n",
        "\n",
        "        return r_lane, p_lane, cnt_gt, cnt_pred\n",
        "\n",
        "    # evaluate two dataset at varying lane probability threshold to calculate AP\n",
        "    def bench_one_submit_varying_probs(self, pred_file, gt_file, eval_out_file=None, eval_fig_file=None):\n",
        "        varying_th = np.linspace(0.05, 0.95, 19)\n",
        "        # try:\n",
        "        pred_lines = open(pred_file).readlines()\n",
        "        json_pred = [json.loads(line) for line in pred_lines]\n",
        "        # except BaseException as e:\n",
        "        #     raise Exception('Fail to load json file of the prediction.')\n",
        "        json_gt = [json.loads(line) for line in open(gt_file).readlines()]\n",
        "        if len(json_gt) != len(json_pred):\n",
        "            raise Exception('We do not get the predictions of all the test tasks')\n",
        "        gts = {l['raw_file']: l for l in json_gt}\n",
        "\n",
        "        laneline_r_all = []\n",
        "        laneline_p_all = []\n",
        "        laneline_gt_cnt_all = []\n",
        "        laneline_pred_cnt_all = []\n",
        "        centerline_r_all = []\n",
        "        centerline_p_all = []\n",
        "        centerline_gt_cnt_all = []\n",
        "        centerline_pred_cnt_all = []\n",
        "        for i, pred in enumerate(json_pred):\n",
        "            print('Evaluating sample {} / {}'.format(i, len(json_pred)))\n",
        "            if 'raw_file' not in pred or 'laneLines' not in pred:\n",
        "                raise Exception('raw_file or lanelines not in some predictions.')\n",
        "            raw_file = pred['raw_file']\n",
        "\n",
        "            pred_lanelines = pred['laneLines']\n",
        "            pred_laneLines_prob = pred['laneLines_prob']\n",
        "            if raw_file not in gts:\n",
        "                raise Exception('Some raw_file from your predictions do not exist in the test tasks.')\n",
        "            gt = gts[raw_file]\n",
        "            gt_cam_height = gt['cam_height']\n",
        "            gt_cam_pitch = gt['cam_pitch']\n",
        "\n",
        "            # evaluate lanelines\n",
        "            gt_lanelines = gt['laneLines']\n",
        "            gt_visibility = gt['laneLines_visibility']\n",
        "            r_lane_vec = []\n",
        "            p_lane_vec = []\n",
        "            cnt_gt_vec = []\n",
        "            cnt_pred_vec = []\n",
        "\n",
        "            for prob_th in varying_th:\n",
        "                pred_lanelines = [pred_lanelines[ii] for ii in range(len(pred_laneLines_prob)) if\n",
        "                                  pred_laneLines_prob[ii] > prob_th]\n",
        "                pred_laneLines_prob = [prob for prob in pred_laneLines_prob if prob > prob_th]\n",
        "                pred_lanelines_copy = copy.deepcopy(pred_lanelines)\n",
        "                # N to N matching of lanelines\n",
        "                r_lane, p_lane, cnt_gt, cnt_pred = self.bench_PR(pred_lanelines_copy,\n",
        "                                                                 gt_lanelines,\n",
        "                                                                 gt_visibility)\n",
        "                r_lane_vec.append(r_lane)\n",
        "                p_lane_vec.append(p_lane)\n",
        "                cnt_gt_vec.append(cnt_gt)\n",
        "                cnt_pred_vec.append(cnt_pred)\n",
        "\n",
        "            laneline_r_all.append(r_lane_vec)\n",
        "            laneline_p_all.append(p_lane_vec)\n",
        "            laneline_gt_cnt_all.append(cnt_gt_vec)\n",
        "            laneline_pred_cnt_all.append(cnt_pred_vec)\n",
        "\n",
        "            # evaluate centerlines\n",
        "            if not self.no_centerline:\n",
        "                pred_centerlines = pred['centerLines']\n",
        "                pred_centerLines_prob = pred['centerLines_prob']\n",
        "                gt_centerlines = gt['centerLines']\n",
        "                gt_visibility = gt['centerLines_visibility']\n",
        "                r_lane_vec = []\n",
        "                p_lane_vec = []\n",
        "                cnt_gt_vec = []\n",
        "                cnt_pred_vec = []\n",
        "\n",
        "                for prob_th in varying_th:\n",
        "                    pred_centerlines = [pred_centerlines[ii] for ii in range(len(pred_centerLines_prob)) if\n",
        "                                        pred_centerLines_prob[ii] > prob_th]\n",
        "                    pred_centerLines_prob = [prob for prob in pred_centerLines_prob if prob > prob_th]\n",
        "                    pred_centerlines_copy = copy.deepcopy(pred_centerlines)\n",
        "                    # N to N matching of lanelines\n",
        "                    r_lane, p_lane, cnt_gt, cnt_pred = self.bench_PR(pred_centerlines_copy,\n",
        "                                                                     gt_centerlines,\n",
        "                                                                     gt_visibility)\n",
        "                    r_lane_vec.append(r_lane)\n",
        "                    p_lane_vec.append(p_lane)\n",
        "                    cnt_gt_vec.append(cnt_gt)\n",
        "                    cnt_pred_vec.append(cnt_pred)\n",
        "                centerline_r_all.append(r_lane_vec)\n",
        "                centerline_p_all.append(p_lane_vec)\n",
        "                centerline_gt_cnt_all.append(cnt_gt_vec)\n",
        "                centerline_pred_cnt_all.append(cnt_pred_vec)\n",
        "\n",
        "        output_stats = []\n",
        "        # compute precision, recall\n",
        "        laneline_r_all = np.array(laneline_r_all)\n",
        "        laneline_p_all = np.array(laneline_p_all)\n",
        "        laneline_gt_cnt_all = np.array(laneline_gt_cnt_all)\n",
        "        laneline_pred_cnt_all = np.array(laneline_pred_cnt_all)\n",
        "\n",
        "        R_lane = np.sum(laneline_r_all, axis=0) / (np.sum(laneline_gt_cnt_all, axis=0) + 1e-6)\n",
        "        P_lane = np.sum(laneline_p_all, axis=0) / (np.sum(laneline_pred_cnt_all, axis=0) + 1e-6)\n",
        "        F_lane = 2 * R_lane * P_lane / (R_lane + P_lane + 1e-6)\n",
        "\n",
        "        output_stats.append(F_lane)\n",
        "        output_stats.append(R_lane)\n",
        "        output_stats.append(P_lane)\n",
        "\n",
        "        if not self.no_centerline:\n",
        "            centerline_r_all = np.array(centerline_r_all)\n",
        "            centerline_p_all = np.array(centerline_p_all)\n",
        "            centerline_gt_cnt_all = np.array(centerline_gt_cnt_all)\n",
        "            centerline_pred_cnt_all = np.array(centerline_pred_cnt_all)\n",
        "\n",
        "            R_lane = np.sum(centerline_r_all, axis=0) / (np.sum(centerline_gt_cnt_all, axis=0) + 1e-6)\n",
        "            P_lane = np.sum(centerline_p_all, axis=0) / (np.sum(centerline_pred_cnt_all, axis=0) + 1e-6)\n",
        "            F_lane = 2 * R_lane * P_lane / (R_lane + P_lane + 1e-6)\n",
        "\n",
        "            output_stats.append(F_lane)\n",
        "            output_stats.append(R_lane)\n",
        "            output_stats.append(P_lane)\n",
        "\n",
        "        # calculate metrics\n",
        "        laneline_F = output_stats[0]\n",
        "        laneline_F_max = np.max(laneline_F)\n",
        "        laneline_max_i = np.argmax(laneline_F)\n",
        "        laneline_R = output_stats[1]\n",
        "        laneline_P = output_stats[2]\n",
        "        centerline_F = output_stats[3]\n",
        "        centerline_F_max = centerline_F[laneline_max_i]\n",
        "        centerline_max_i = laneline_max_i\n",
        "        centerline_R = output_stats[4]\n",
        "        centerline_P = output_stats[5]\n",
        "\n",
        "        laneline_R = np.array([1.] + laneline_R.tolist() + [0.])\n",
        "        laneline_P = np.array([0.] + laneline_P.tolist() + [1.])\n",
        "        centerline_R = np.array([1.] + centerline_R.tolist() + [0.])\n",
        "        centerline_P = np.array([0.] + centerline_P.tolist() + [1.])\n",
        "        f_laneline = interp1d(laneline_R, laneline_P)\n",
        "        f_centerline = interp1d(centerline_R, centerline_P)\n",
        "        r_range = np.linspace(0.05, 0.95, 19)\n",
        "        laneline_AP = np.mean(f_laneline(r_range))\n",
        "        centerline_AP = np.mean(f_centerline(r_range))\n",
        "\n",
        "        if eval_fig_file is not None:\n",
        "            # plot PR curve\n",
        "            fig = plt.figure()\n",
        "            ax1 = fig.add_subplot(121)\n",
        "            ax2 = fig.add_subplot(122)\n",
        "            ax1.plot(laneline_R, laneline_P, '-s')\n",
        "            ax2.plot(centerline_R, centerline_P, '-s')\n",
        "\n",
        "            ax1.set_xlim(0, 1)\n",
        "            ax1.set_ylim(0, 1)\n",
        "            ax1.set_title('Lane Line')\n",
        "            ax1.set_xlabel('Recall')\n",
        "            ax1.set_ylabel('Precision')\n",
        "            ax1.set_aspect('equal')\n",
        "            ax1.legend('Max F-measure {:.3}'.format(laneline_F_max))\n",
        "\n",
        "            ax2.set_xlim(0, 1)\n",
        "            ax2.set_ylim(0, 1)\n",
        "            ax2.set_title('Center Line')\n",
        "            ax2.set_xlabel('Recall')\n",
        "            ax2.set_ylabel('Precision')\n",
        "            ax2.set_aspect('equal')\n",
        "            ax2.legend('Max F-measure {:.3}'.format(centerline_F_max))\n",
        "\n",
        "            # fig.subplots_adjust(wspace=0.1, hspace=0.01)\n",
        "            fig.savefig(eval_fig_file)\n",
        "            plt.close(fig)\n",
        "\n",
        "        # print(\"===> Evaluation on validation set: \\n\"\n",
        "        #       \"laneline max F-measure {:.3} at Recall {:.3}, Precision {:.3} \\n\"\n",
        "        #       \"laneline AP: {:.3}\\n\"\n",
        "        #       \"centerline max F-measure {:.3} at Recall {:.3}, Precision {:.3} \\n\"\n",
        "        #       \"centerline AP: {:.3} \\n\".format(laneline_F_max,\n",
        "        #                                        laneline_R[laneline_max_i + 1],\n",
        "        #                                        laneline_P[laneline_max_i + 1],\n",
        "        #                                        laneline_AP,\n",
        "        #                                        centerline_F_max,\n",
        "        #                                        centerline_R[centerline_max_i + 1],\n",
        "        #                                        centerline_P[centerline_max_i + 1],\n",
        "        #                                        centerline_AP))\n",
        "\n",
        "        json_out = {}\n",
        "        json_out['laneline_R'] = laneline_R[1:-1].astype(np.float32).tolist()\n",
        "        json_out['laneline_P'] = laneline_P[1:-1].astype(np.float32).tolist()\n",
        "        json_out['laneline_F_max'] = laneline_F_max\n",
        "        json_out['laneline_max_i'] = laneline_max_i.tolist()\n",
        "        json_out['laneline_AP'] = laneline_AP\n",
        "\n",
        "        json_out['centerline_R'] = centerline_R[1:-1].astype(np.float32).tolist()\n",
        "        json_out['centerline_P'] = centerline_P[1:-1].astype(np.float32).tolist()\n",
        "        json_out['centerline_F_max'] = centerline_F_max\n",
        "        json_out['centerline_max_i'] = centerline_max_i.tolist()\n",
        "        json_out['centerline_AP'] = centerline_AP\n",
        "\n",
        "        json_out['max_F_prob_th'] = varying_th[laneline_max_i]\n",
        "\n",
        "        if eval_out_file is not None:\n",
        "            with open(eval_out_file, 'w') as jsonFile:\n",
        "                jsonFile.write(json.dumps(json_out))\n",
        "                jsonFile.write('\\n')\n",
        "                jsonFile.close()\n",
        "        return json_out\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    vis = False\n",
        "    parser = define_args()\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # two method are compared: '3D_LaneNet' and 'Gen_LaneNet'\n",
        "    method_name = 'Gen_LaneNet_ext'\n",
        "\n",
        "    # Three different splits of datasets: 'standard', 'rare_subsit', 'illus_chg'\n",
        "    data_split = 'illus_chg'\n",
        "\n",
        "    # location where the original dataset is saved. Image will be loaded in case of visualization\n",
        "    args.dataset_dir = '~/Datasets/Apollo_Sim_3D_Lane_Release/'\n",
        "\n",
        "    # load configuration for certain dataset\n",
        "    sim3d_config(args)\n",
        "\n",
        "    # auto-file in dependent paths\n",
        "    gt_file = 'data_splits/' + data_split + '/test.json'\n",
        "    pred_folder = 'data_splits/' + data_split + '/' + method_name\n",
        "    pred_file = pred_folder + '/test_pred_file.json'\n",
        "\n",
        "    # Initialize evaluator\n",
        "    evaluator = LaneEval(args)\n",
        "\n",
        "    # evaluation at varying thresholds\n",
        "    eval_stats_pr = evaluator.bench_one_submit_varying_probs(pred_file, gt_file)\n",
        "    max_f_prob = eval_stats_pr['max_F_prob_th']\n",
        "\n",
        "    # evaluate at the point with max F-measure. Additional eval of position error. Option to visualize matching result\n",
        "    eval_stats = evaluator.bench_one_submit(pred_file, gt_file, prob_th=max_f_prob, vis=vis)\n",
        "\n",
        "    print(\"Metrics: AP, F-score, x error (close), x error (far), z error (close), z error (far)\")\n",
        "    print(\n",
        "        \"Laneline:  {:.3}  {:.3}  {:.3}  {:.3}  {:.3}  {:.3}\".format(eval_stats_pr['laneline_AP'], eval_stats[0],\n",
        "                                                                     eval_stats[3], eval_stats[4],\n",
        "                                                                     eval_stats[5], eval_stats[6]))\n",
        "    print(\"Centerline:  {:.3}  {:.3}  {:.3}  {:.3}  {:.3}  {:.3}\".format(eval_stats_pr['centerline_AP'], eval_stats[7],\n",
        "                                                                         eval_stats[10], eval_stats[11],\n",
        "                                                                         eval_stats[12], eval_stats[13]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}